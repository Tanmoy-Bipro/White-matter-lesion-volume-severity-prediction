{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"},"colab":{"name":"WML_CSV_-latest_MEAN_MEDIAN_STD_soho-Copy1.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"1MQINaKzBJCg","colab_type":"code","colab":{},"outputId":"29b13b6e-01f9-49f9-f387-6dd7eb502dc4"},"source":["\n","import pandas as pd\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import accuracy_score\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import accuracy_score\n","from sklearn.grid_search import GridSearchCV\n","from sklearn import datasets, svm\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import LeaveOneOut\n","#df = pd.read_csv('wml_data.csv', header = 0)\n","#df = pd.read_csv('wml_avn_fan_op.csv', header = 0)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["C:\\Users\\Public\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n","  \"This module will be removed in 0.20.\", DeprecationWarning)\n","C:\\Users\\Public\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n","  DeprecationWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"DfJ4CUi_BJCl","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PUKhtEbmBJCo","colab_type":"code","colab":{},"outputId":"6c51764c-baf3-4477-84eb-03b6236157f8"},"source":["#multivariate linear regression\n","#80/20 split- 20% training data\n","'''\n","\n","array = df[\"WML-BR2\"].tolist()\n","\n","array\n","array_grouped=[]\n","for idx, item in enumerate(array):\n","    if  (item>0) & (item<1424) :\n","        array_grouped.append(1) ;\n","    elif (item>=1424) & (item<2849):\n","        array_grouped.append(2) \n","    elif item>2849:\n","        array_grouped.append(3) ;#print(item)\n","print(array_grouped,array)\n","df['wml'] = array_grouped\n","#train, test = train_test_split(fifa_dataset, test_size=0.2)  // fifa_dataset here is a panda dataframe\n","\n","train, test = train_test_split(df, test_size=0.1)\n","df.tail(2)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"EOF while scanning triple-quoted string literal (<ipython-input-27-d35404fcef0c>, line 21)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-d35404fcef0c>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    df.tail(2)\u001b[0m\n\u001b[0m              \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"]}]},{"cell_type":"code","metadata":{"id":"OpQvX6o6BJCr","colab_type":"code","colab":{}},"source":["\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"un0aI8lVBJCt","colab_type":"code","colab":{}},"source":["#independent and dependent variables\n","##features= ['Agility', 'Acceleration', 'Balance','Reactions','Positioning','Skill Moves','BallControl','Crossing','Finishing']\n","##target = 'SprintSpeed'\n","#target\n","'''\n","data_avn=train.iloc[:,[12,13,14,15,16,17,30,31,32,33,34,35]]\n","data_avn_fan = train.iloc[:,[12,13,14,15,16,17,30,31,32,33,34,35,18,19,20,21,22,23, 36,37,38,39,40,41  ]]\n","data_fan=train.iloc[:,[18,19,20,21,22,23, 36,37,38,39,40,41]]\n","\n","target_1col = train.iloc[:,[1]]\n","#target_1col = train['wml'] \n","#print(data_avn_fan, target_1col)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VPmGsJhfBJCw","colab_type":"code","colab":{},"outputId":"e342bb05-abff-42a9-fce7-2705a6567c9f"},"source":["#multivariate linear regression NEW BLOCK \n","#80/20 split- 20% training data\n","\n","#train, test = train_test_split(fifa_dataset, test_size=0.2)  // fifa_dataset here is a panda dataframe\n","\n","\n","\n","data_avn = pd.read_csv('wml_avn_label.csv', header = 0)\n","\n","data_fan = pd.read_csv('wml_fan_label.csv', header = 0)\n","\n","data_avn_fan = pd.read_csv('wml_avn_fan_label.csv', header = 0)\n","\n","data_avn_fan_op = pd.read_csv('wml_avn_fan_op_label.csv', header = 0)\n","\n","data_op = pd.read_csv('wml_op_label.csv', header = 0)\n","#label = pd.read_csv('wml_label.csv', header = 0)\n","\n","\n","\n","\n","\n","# for avn_fan_op\n","df2 = data_avn_fan_op  ##############################################################################\n","\n","train, test = train_test_split(df2, test_size=0.1)\n","\n","y_train_true = train.iloc[:,[0]]\n","\n","y_test_true = test.iloc[:,[0]]\n","\n","x_train = train.iloc[:,1:22] #-----------------------------------------------\n","\n","x_test = test.iloc[:,1: 22]\n","\n","print( x_train , y_train_true)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["     0       0.1  0.2      0.3       0.4  0.5      0.6   1  0.7  1.1  ...   \\\n","76   2  0.333330    0  0.77850  1.083300  0.0  1.78160   3    4    1  ...    \n","70   1  0.083333    0  0.28868  0.666670  0.0  1.23090   4    4    5  ...    \n","87   2  0.166670    0  0.57735  0.416670  0.0  0.79296   3    2    8  ...    \n","51   0  0.000000    0  0.00000  0.166670  0.0  0.57735   1    2    9  ...    \n","25   3  0.333330    0  0.88763  0.666670  0.0  0.98473   4    2    3  ...    \n","2    0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1  ...    \n","68   1  0.083333    0  0.28868  0.083333  0.0  0.28868  12    1    8  ...    \n","39   0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1  ...    \n","30   4  0.583330    0  1.24010  0.333330  0.0  1.15470   8    4    9  ...    \n","110  2  0.333330    0  0.65134  0.166670  0.0  0.57735   4    2    4  ...    \n","17   2  0.416670    0  0.79296  0.000000  0.0  0.00000   5    0    1  ...    \n","120  1  0.083333    0  0.28868  0.083333  0.0  0.28868   6    1    8  ...    \n","43   1  0.250000    0  0.45227  0.083333  0.0  0.28868   1    1    9  ...    \n","114  1  0.083333    0  0.28868  0.000000  0.0  0.00000   3    0    1  ...    \n","80   2  0.750000    0  0.96531  0.000000  0.0  0.00000   4    0    1  ...    \n","109  1  0.166670    0  0.38925  0.000000  0.0  0.00000   3    0    1  ...    \n","66   0  0.000000    0  0.00000  0.666670  0.0  1.30270   1    4   12  ...    \n","23   0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1  ...    \n","81   2  0.583330    0  0.79296  0.166670  0.0  0.57735   9    2    4  ...    \n","130  1  0.083333    0  0.28868  0.000000  0.0  0.00000   3    0    1  ...    \n","1    0  0.000000    0  0.00000  0.916670  0.0  1.56430   1    4    2  ...    \n","102  1  0.083333    0  0.28868  0.000000  0.0  0.00000   3    0    1  ...    \n","32   1  0.166670    0  0.38925  0.083333  0.0  0.28868   3    1    9  ...    \n","50   2  0.166670    0  0.57735  0.000000  0.0  0.00000   8    0    1  ...    \n","28   1  0.083333    0  0.28868  0.833330  0.0  1.02990   1    2    1  ...    \n","89   4  0.833330    0  1.58590  0.333330  0.0  0.77850   9    2    4  ...    \n","15   1  0.083333    0  0.28868  0.083333  0.0  0.28868   1    1    5  ...    \n","60   2  0.166670    0  0.57735  0.333330  0.0  0.77850   4    2    8  ...    \n","74   4  1.333300    1  1.49750  0.500000  0.0  0.79772   9    2    6  ...    \n","129  1  0.083333    0  0.28868  0.000000  0.0  0.00000   4    0    1  ...    \n","..  ..       ...  ...      ...       ...  ...      ...  ..  ...  ...  ...    \n","123  2  0.166670    0  0.57735  0.000000  0.0  0.00000   4    0    1  ...    \n","59   1  0.083333    0  0.28868  0.083333  0.0  0.28868   4    1   10  ...    \n","91   2  0.666670    0  0.98473  0.000000  0.0  0.00000   8    0    1  ...    \n","52   2  0.166670    0  0.57735  0.083333  0.0  0.28868   3    1    8  ...    \n","83   3  0.916670    0  1.16450  0.166670  0.0  0.57735   4    2    9  ...    \n","99   2  0.166670    0  0.57735  0.333330  0.0  0.77850   5    2    3  ...    \n","40   2  0.333330    0  0.77850  0.750000  0.5  0.86603   4    2    3  ...    \n","12   0  0.000000    0  0.00000  0.250000  0.0  0.62158   1    2    8  ...    \n","14   1  0.083333    0  0.28868  0.000000  0.0  0.00000   4    0    1  ...    \n","41   2  0.166670    0  0.57735  0.583330  0.0  0.90034   3    2    2  ...    \n","56   4  1.083300    0  1.56430  0.166670  0.0  0.57735   9    2    9  ...    \n","77   2  0.166670    0  0.57735  1.666700  2.0  1.66970  10    4    3  ...    \n","115  1  0.083333    0  0.28868  0.000000  0.0  0.00000   4    0    1  ...    \n","22   1  0.083333    0  0.28868  0.166670  0.0  0.57735   4    2    9  ...    \n","49   1  0.083333    0  0.28868  0.166670  0.0  0.57735   3    2    2  ...    \n","90   4  0.416670    0  1.16450  0.333330  0.0  0.77850   4    2    6  ...    \n","47   0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1  ...    \n","125  0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1  ...    \n","78   1  0.083333    0  0.28868  0.916670  0.0  1.56430   5    4    3  ...    \n","100  2  0.166670    0  0.57735  0.083333  0.0  0.28868  10    1    9  ...    \n","64   1  0.083333    0  0.28868  0.000000  0.0  0.00000   4    0    1  ...    \n","5    0  0.000000    0  0.00000  0.083333  0.0  0.28868   1    1    6  ...    \n","82   2  0.166670    0  0.57735  0.750000  0.0  1.28810   3    4    5  ...    \n","24   2  1.000000    1  0.85280  0.250000  0.0  0.62158   8    2    1  ...    \n","108  0  0.000000    0  0.00000  0.166670  0.0  0.38925   1    1    9  ...    \n","19   4  1.000000    0  1.80910  0.000000  0.0  0.00000   8    0    1  ...    \n","75   2  0.500000    0  0.90453  1.333300  1.5  1.15470   3    3    9  ...    \n","88   2  0.250000    0  0.62158  0.250000  0.0  0.62158   3    2    8  ...    \n","45   0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1  ...    \n","95   0  0.000000    0  0.00000  0.500000  0.0  0.79772   1    2    6  ...    \n","\n","     1.2  0.9  0.10  0.11  0.12  0.13  0.14  0.15  0.16  0.17  \n","76     2    4     0     9     4     5    14     4    13    19  \n","70     4    1     0     7     1     7     0     1     8     7  \n","87     1    2     0     0     5     0     0     2     5     0  \n","51     8    0     0     0     2     0     1     0     2     1  \n","25     2    4     0     6     2     6     0     4     8     6  \n","2      1    0     0     0     0     0     0     0     0     0  \n","68     8    0     1     0     1     0     1     1     1     1  \n","39     7    0     0     0     0     0     1     0     0     1  \n","30     1    1     6     0     4     0     0     7     4     0  \n","110    3    4     0     2     0     2     0     4     2     2  \n","17     1    3     2     0     0     0     0     5     0     0  \n","120    1    1     0     0     1     0     0     1     1     0  \n","43     1    3     0     0     1     0     0     3     1     0  \n","114    1    1     0     0     0     0     0     1     0     0  \n","80     6    4     5     0     0     2     0     9     0     2  \n","109    1    2     0     0     0     0     0     2     0     0  \n","66     1    0     0     4     4     2     2     0     8     4  \n","23     1    0     0     0     0     0     0     0     0     0  \n","81     3    3     4     2     0     2     2     7     2     4  \n","130    1    1     0     0     0     0     0     1     0     0  \n","1      1    0     0     9     2     9     2     0    11    11  \n","102    1    1     0     0     0     0     0     1     0     0  \n","32     1    2     0     0     1     0     0     2     1     0  \n","50     1    0     2     0     0     0     0     2     0     0  \n","28     1    1     0     8     2     6     2     1    10     8  \n","89     3    2     8     4     0     4     0    10     4     4  \n","15     4    1     0     1     0     1     0     1     1     1  \n","60     1    2     0     0     4     0     0     2     4     0  \n","74     5    4    12     2     4     2     4    16     6     6  \n","129    1    1     0     0     0     0     0     1     0     0  \n","..   ...  ...   ...   ...   ...   ...   ...   ...   ...   ...  \n","123    1    2     0     0     0     0     0     2     0     0  \n","59     9    1     0     0     1     0     1     1     1     1  \n","91     1    0     8     0     0     0     0     8     0     0  \n","52     1    2     0     0     1     0     0     2     1     0  \n","83     1    3     8     0     2     0     0    11     2     0  \n","99     2    2     0     2     2     2     0     2     4     2  \n","40     8    4     0     4     5     4     6     4     9    10  \n","12     1    0     0     0     3     0     0     0     3     0  \n","14     1    1     0     0     0     0     0     1     0     0  \n","41     9    2     0     7     0     6     4     2     7    10  \n","56     6    1    12     0     2     2     4    13     2     6  \n","77     2    0     2    10    10    10     0     2    20    10  \n","115    1    1     0     0     0     0     0     1     0     0  \n","22     1    1     0     0     2     0     0     1     2     0  \n","49     1    1     0     2     0     2     0     1     2     2  \n","90     5    5     0     2     2     2     0     5     4     2  \n","47     1    0     0     0     0     0     0     0     0     0  \n","125    1    0     0     0     0     0     0     0     0     0  \n","78     2    1     0     9     2     8     4     1    11    12  \n","100    1    0     2     0     1     0     0     2     1     0  \n","64     1    1     0     0     0     0     0     1     0     0  \n","5      5    0     0     1     0     1     0     0     1     1  \n","82     4    2     0     8     1     6     0     2     9     6  \n","24    10    3     9     2     1     1     4    12     3     5  \n","108    1    0     0     0     2     0     0     0     2     0  \n","19     1    0    12     0     0     0     0    12     0     0  \n","75     8    6     0     8     8     7    10     6    16    17  \n","88     1    3     0     0     3     0     0     3     3     0  \n","45     1    0     0     0     0     0     0     0     0     0  \n","95     5    0     0     2     4     2     2     0     6     4  \n","\n","[118 rows x 21 columns]      3\n","76   1\n","70   3\n","87   2\n","51   3\n","25   3\n","2    3\n","68   2\n","39   2\n","30   2\n","110  2\n","17   3\n","120  1\n","43   1\n","114  2\n","80   2\n","109  2\n","66   1\n","23   1\n","81   3\n","130  1\n","1    3\n","102  1\n","32   3\n","50   3\n","28   1\n","89   3\n","15   1\n","60   3\n","74   3\n","129  2\n","..  ..\n","123  1\n","59   2\n","91   1\n","52   1\n","83   1\n","99   3\n","40   1\n","12   1\n","14   3\n","41   3\n","56   3\n","77   1\n","115  3\n","22   2\n","49   2\n","90   3\n","47   2\n","125  1\n","78   3\n","100  2\n","64   1\n","5    1\n","82   2\n","24   3\n","108  2\n","19   1\n","75   3\n","88   2\n","45   1\n","95   1\n","\n","[118 rows x 1 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7Ow96A5XBJCy","colab_type":"code","colab":{},"outputId":"55b2882d-8b17-42a8-f315-f707c1ef18a0"},"source":["# for avn_fan\n","df2 = data_avn_fan  ##############################################################################\n","\n","train, test = train_test_split(df2, test_size=0.1)\n","\n","y_train_true = train.iloc[:,[0]]\n","\n","y_test_true = test.iloc[:,[0]]\n","\n","x_train = train.iloc[:,1:17] #-----------------------------------------------\n","\n","x_test = test.iloc[:,1: 17]\n","\n","print( x_train , y_train_true)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["     0       0.1  0.2      0.3       0.4  0.5      0.6   1  0.7  1.1  0.8  \\\n","18   2  0.250000    0  0.62158  0.166670  0.0  0.38925   9    1    4    0   \n","22   1  0.083333    0  0.28868  0.166670  0.0  0.57735   4    2    9    1   \n","71   0  0.000000    0  0.00000  0.416670  0.0  0.79296   1    2    1    0   \n","76   2  0.333330    0  0.77850  1.083300  0.0  1.78160   3    4    1    4   \n","44   1  0.083333    0  0.28868  0.000000  0.0  0.00000   3    0    1    1   \n","77   2  0.166670    0  0.57735  1.666700  2.0  1.66970  10    4    3    0   \n","21   1  0.083333    0  0.28868  0.166670  0.0  0.57735   3    2    3    1   \n","95   0  0.000000    0  0.00000  0.500000  0.0  0.79772   1    2    6    0   \n","38   2  0.250000    0  0.62158  0.416670  0.0  0.79296   4    2    4    3   \n","78   1  0.083333    0  0.28868  0.916670  0.0  1.56430   5    4    3    1   \n","29   0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1    0   \n","53   0  0.000000    0  0.00000  0.166670  0.0  0.57735   1    2    9    0   \n","20   1  0.166670    0  0.38925  0.166670  0.0  0.57735   8    2    6    0   \n","39   0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1    0   \n","81   2  0.583330    0  0.79296  0.166670  0.0  0.57735   9    2    4    3   \n","49   1  0.083333    0  0.28868  0.166670  0.0  0.57735   3    2    2    1   \n","101  0  0.000000    0  0.00000  0.083333  0.0  0.28868   1    1    8    0   \n","68   1  0.083333    0  0.28868  0.083333  0.0  0.28868  12    1    8    0   \n","57   2  0.666670    0  0.98473  0.333330  0.0  1.15470   1    4    4    4   \n","103  1  0.083333    0  0.28868  0.000000  0.0  0.00000   5    0    1    1   \n","102  1  0.083333    0  0.28868  0.000000  0.0  0.00000   3    0    1    1   \n","3    4  0.333330    0  1.15470  0.000000  0.0  0.00000   5    0    1    4   \n","96   1  0.083333    0  0.28868  0.250000  0.0  0.62158   4    2    8    1   \n","63   0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1    0   \n","12   0  0.000000    0  0.00000  0.250000  0.0  0.62158   1    2    8    0   \n","128  1  0.083333    0  0.28868  0.083333  0.0  0.28868   3    1    9    1   \n","45   0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1    0   \n","55   1  0.083333    0  0.28868  2.416700  3.0  1.78160   3    4    2    1   \n","50   2  0.166670    0  0.57735  0.000000  0.0  0.00000   8    0    1    0   \n","99   2  0.166670    0  0.57735  0.333330  0.0  0.77850   5    2    3    2   \n","..  ..       ...  ...      ...       ...  ...      ...  ..  ...  ...  ...   \n","84   1  0.083333    0  0.28868  0.750000  0.0  0.96531   4    2    1    1   \n","67   2  0.333330    0  0.77850  0.416670  0.0  0.66856   3    2    3    4   \n","34   0  0.000000    0  0.00000  0.250000  0.0  0.62158   1    2    3    0   \n","115  1  0.083333    0  0.28868  0.000000  0.0  0.00000   4    0    1    1   \n","79   2  0.416670    0  0.79296  0.916670  0.0  1.56430   3    4    1    5   \n","120  1  0.083333    0  0.28868  0.083333  0.0  0.28868   6    1    8    1   \n","6    2  0.250000    0  0.62158  0.000000  0.0  0.00000   4    0    1    2   \n","108  0  0.000000    0  0.00000  0.166670  0.0  0.38925   1    1    9    0   \n","109  1  0.166670    0  0.38925  0.000000  0.0  0.00000   3    0    1    2   \n","116  0  0.000000    0  0.00000  0.083333  0.0  0.28868   1    1   11    0   \n","124  0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1    0   \n","16   0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1    0   \n","8    1  0.083333    0  0.28868  0.000000  0.0  0.00000   5    0    1    1   \n","72   1  0.083333    0  0.28868  0.166670  0.0  0.57735   3    2    9    1   \n","118  0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1    0   \n","15   1  0.083333    0  0.28868  0.083333  0.0  0.28868   1    1    5    1   \n","60   2  0.166670    0  0.57735  0.333330  0.0  0.77850   4    2    8    2   \n","117  0  0.000000    0  0.00000  0.083333  0.0  0.28868   1    1    3    0   \n","32   1  0.166670    0  0.38925  0.083333  0.0  0.28868   3    1    9    2   \n","125  0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1    0   \n","97   3  0.416670    0  0.90034  0.166670  0.0  0.57735   4    2    9    5   \n","73   4  0.583330    0  1.37900  1.750000  1.0  1.91290   4    4    1    7   \n","19   4  1.000000    0  1.80910  0.000000  0.0  0.00000   8    0    1    0   \n","94   2  0.250000    0  0.62158  0.166670  0.0  0.57735  12    2    9    1   \n","65   2  0.333330    0  0.65134  0.416670  0.0  0.79296   8    2    9    2   \n","98   0  0.000000    0  0.00000  0.250000  0.0  0.62158   1    2    9    0   \n","104  2  0.166670    0  0.57735  0.166670  0.0  0.38925   4    1    3    2   \n","85   1  0.083333    0  0.28868  0.666670  0.0  1.23090  12    4   12    0   \n","42   0  0.000000    0  0.00000  0.250000  0.0  0.62158   1    2    2    0   \n","28   1  0.083333    0  0.28868  0.833330  0.0  1.02990   1    2    1    1   \n","\n","     0.9  0.10  0.11  0.12  0.13  \n","18     3     1     1     3     2  \n","22     0     0     2     1     2  \n","71     0     4     1     0     5  \n","76     0     9     4     4    13  \n","44     0     0     0     1     0  \n","77     2    10    10     2    20  \n","21     0     2     0     1     2  \n","95     0     2     4     0     6  \n","38     0     2     3     3     5  \n","78     0     9     2     1    11  \n","29     0     0     0     0     0  \n","53     0     0     2     0     2  \n","20     2     2     0     2     2  \n","39     0     0     0     0     0  \n","81     4     2     0     7     2  \n","49     0     2     0     1     2  \n","101    0     0     1     0     1  \n","68     1     0     1     1     1  \n","57     4     4     0     8     4  \n","103    0     0     0     1     0  \n","102    0     0     0     1     0  \n","3      0     0     0     4     0  \n","96     0     0     3     1     3  \n","63     0     0     0     0     0  \n","12     0     0     3     0     3  \n","128    0     0     1     1     1  \n","45     0     0     0     0     0  \n","55     0    21     8     1    29  \n","50     2     0     0     2     0  \n","99     0     2     2     2     4  \n","..   ...   ...   ...   ...   ...  \n","84     0     4     5     1     9  \n","67     0     4     1     4     5  \n","34     0     3     0     0     3  \n","115    0     0     0     1     0  \n","79     0     8     3     5    11  \n","120    0     0     1     1     1  \n","6      1     0     0     3     0  \n","108    0     0     2     0     2  \n","109    0     0     0     2     0  \n","116    0     0     1     0     1  \n","124    0     0     0     0     0  \n","16     0     0     0     0     0  \n","8      0     0     0     1     0  \n","72     0     0     2     1     2  \n","118    0     0     0     0     0  \n","15     0     1     0     1     1  \n","60     0     0     4     2     4  \n","117    0     1     0     0     1  \n","32     0     0     1     2     1  \n","125    0     0     0     0     0  \n","97     0     0     2     5     2  \n","73     0    14     7     7    21  \n","19    12     0     0    12     0  \n","94     2     0     2     3     2  \n","65     2     0     5     4     5  \n","98     0     0     3     0     3  \n","104    0     1     1     2     2  \n","85     1     4     4     1     8  \n","42     0     3     0     0     3  \n","28     0     8     2     1    10  \n","\n","[118 rows x 16 columns]      3\n","18   3\n","22   2\n","71   2\n","76   1\n","44   1\n","77   1\n","21   2\n","95   1\n","38   3\n","78   3\n","29   2\n","53   2\n","20   3\n","39   2\n","81   3\n","49   2\n","101  2\n","68   2\n","57   3\n","103  3\n","102  1\n","3    3\n","96   3\n","63   1\n","12   1\n","128  1\n","45   1\n","55   1\n","50   3\n","99   3\n","..  ..\n","84   1\n","67   2\n","34   1\n","115  3\n","79   3\n","120  1\n","6    2\n","108  2\n","109  2\n","116  1\n","124  1\n","16   1\n","8    1\n","72   2\n","118  1\n","15   1\n","60   3\n","117  2\n","32   3\n","125  1\n","97   3\n","73   3\n","19   1\n","94   3\n","65   3\n","98   2\n","104  3\n","85   2\n","42   2\n","28   1\n","\n","[118 rows x 1 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a7OviumBBJC0","colab_type":"code","colab":{},"outputId":"18849bb0-6b84-4b9e-f620-19ccb99a31a4"},"source":["# for avn\n","df2 = data_avn  ##############################################################################\n","\n","train, test = train_test_split(df2, test_size=0.1)\n","\n","y_train_true = train.iloc[:,[0]]\n","\n","y_test_true = test.iloc[:,[0]]\n","\n","x_train = train.iloc[:,1:8] #-----------------------------------------------\n","\n","x_test = test.iloc[:,1: 8]\n","\n","print( x_train , y_train_true)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["     0   1  0.1  0.2\n","127  0   1    0    0\n","93   2   4    2    0\n","124  0   1    0    0\n","0    0   1    0    0\n","73   4   4    7    0\n","57   2   1    4    4\n","1    0   1    0    0\n","37   0   1    0    0\n","96   1   4    1    0\n","90   4   4    5    0\n","125  0   1    0    0\n","83   3   4    3    8\n","19   4   8    0   12\n","65   2   8    2    2\n","101  0   1    0    0\n","50   2   8    0    2\n","106  0   1    0    0\n","69   0   1    0    0\n","17   2   5    3    2\n","97   3   4    5    0\n","100  2  10    0    2\n","112  0   1    0    0\n","78   1   5    1    0\n","109  1   3    2    0\n","80   2   4    4    5\n","16   0   1    0    0\n","9    2   9    0    2\n","79   2   3    5    0\n","31   0   1    0    0\n","4    0   1    0    0\n","..  ..  ..  ...  ...\n","8    1   5    1    0\n","95   0   1    0    0\n","21   1   3    1    0\n","39   0   1    0    0\n","77   2  10    0    2\n","89   4   9    2    8\n","122  1   6    1    0\n","42   0   1    0    0\n","32   1   3    2    0\n","74   4   9    4   12\n","28   1   1    1    0\n","20   1   8    0    2\n","35   2   2    3    0\n","82   2   3    2    0\n","75   2   3    6    0\n","115  1   4    1    0\n","54   0   1    0    0\n","126  0   1    0    0\n","47   0   1    0    0\n","119  0   1    0    0\n","113  1   4    1    0\n","103  1   5    1    0\n","71   0   1    0    0\n","6    2   4    2    1\n","129  1   4    1    0\n","29   0   1    0    0\n","62   0   1    0    0\n","36   0   1    0    0\n","30   4   8    1    6\n","86   1   4    1    0\n","\n","[118 rows x 4 columns]      3\n","127  1\n","93   3\n","124  1\n","0    3\n","73   3\n","57   3\n","1    3\n","37   1\n","96   3\n","90   3\n","125  1\n","83   1\n","19   1\n","65   3\n","101  2\n","50   3\n","106  1\n","69   1\n","17   3\n","97   3\n","100  2\n","112  3\n","78   3\n","109  2\n","80   2\n","16   1\n","9    3\n","79   3\n","31   1\n","4    2\n","..  ..\n","8    1\n","95   1\n","21   2\n","39   2\n","77   1\n","89   3\n","122  3\n","42   2\n","32   3\n","74   3\n","28   1\n","20   3\n","35   3\n","82   2\n","75   3\n","115  3\n","54   3\n","126  1\n","47   2\n","119  2\n","113  1\n","103  3\n","71   2\n","6    2\n","129  2\n","29   2\n","62   1\n","36   2\n","30   2\n","86   3\n","\n","[118 rows x 1 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-J9DFTdoBJC3","colab_type":"code","colab":{}},"source":["# for fan\n","df2 = data_fan  ##############################################################################\n","\n","train, test = train_test_split(df2, test_size=0.1)\n","\n","y_train_true = train.iloc[:,[0]]\n","\n","y_test_true = test.iloc[:,[0]]\n","\n","x_train = train.iloc[:,1:8] #-----------------------------------------------\n","\n","x_test = test.iloc[:,1: 8]\n","\n","print( x_train , y_train_true)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mwDjzWNPBJC6","colab_type":"code","colab":{},"outputId":"1e85c703-1bf9-43cc-b451-30485a9cb236"},"source":["# for op\n","df2 = data_op  ##############################################################################\n","\n","train, test = train_test_split(df2, test_size=0.1)\n","\n","y_train_true = train.iloc[:,[0]]\n","\n","y_test_true = test.iloc[:,[0]]\n","\n","x_train = train.iloc[:,1:5] #-----------------------------------------------\n","\n","x_test = test.iloc[:,1: 5]\n","\n","print( x_train , y_train_true)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["     0   1  0.1  0.2\n","22   0   1    0    0\n","5    1   5    1    0\n","98   1  10    0    1\n","12   0   1    0    0\n","117  2   7    1    2\n","37   2   1    2    4\n","90   2   5    2    0\n","26   2   8    0    2\n","69   2   8    0    2\n","11   0   1    0    0\n","120  0   1    0    0\n","49   2   1    2    0\n","122  0   1    0    0\n","111  0   1    0    0\n","109  0   1    0    0\n","126  0   1    0    0\n","51   1   8    0    1\n","78   4   2    8    4\n","9    1   3    1    0\n","67   2   2    3    0\n","40   4   8    4    6\n","94   1   8    0    1\n","101  2   8    0    4\n","21   2   2    2    0\n","46   0   1    0    0\n","24   4  10    1    4\n","60   0   1    0    0\n","13   0   1    0    0\n","131  0   1    0    0\n","119  2   7    0    4\n","..  ..  ..  ...  ...\n","81   2   3    2    2\n","33   2   7    0    3\n","4    0   1    0    0\n","100  0   1    0    0\n","87   0   1    0    0\n","47   0   1    0    0\n","23   0   1    0    0\n","110  2   3    2    0\n","6    0   1    0    0\n","105  1   9    0    1\n","74   2   5    2    4\n","79   4   1    4    0\n","43   0   1    0    0\n","116  1   9    0    1\n","121  2   8    1    2\n","18   1   3    1    0\n","73   4   3   10   16\n","15   1   4    1    0\n","114  0   1    0    0\n","130  0   1    0    0\n","129  0   1    0    0\n","63   0   1    0    0\n","83   0   1    0    0\n","39   1   7    0    1\n","61   0   1    0    0\n","82   4   4    6    0\n","56   2   6    2    4\n","42   2   1    3    3\n","96   2   9    0    3\n","52   0   1    0    0\n","\n","[118 rows x 4 columns]      3\n","22   2\n","5    1\n","98   2\n","12   1\n","117  2\n","37   1\n","90   3\n","26   1\n","69   1\n","11   3\n","120  1\n","49   2\n","122  3\n","111  2\n","109  2\n","126  1\n","51   3\n","78   3\n","9    3\n","67   2\n","40   1\n","94   3\n","101  2\n","21   2\n","46   2\n","24   3\n","60   3\n","13   3\n","131  2\n","119  2\n","..  ..\n","81   3\n","33   1\n","4    2\n","100  2\n","87   2\n","47   2\n","23   1\n","110  2\n","6    2\n","105  1\n","74   3\n","79   3\n","43   1\n","116  1\n","121  3\n","18   3\n","73   3\n","15   1\n","114  2\n","130  1\n","129  2\n","63   1\n","83   1\n","39   2\n","61   1\n","82   2\n","56   3\n","42   2\n","96   3\n","52   1\n","\n","[118 rows x 1 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fOXD_ocZBJC9","colab_type":"code","colab":{}},"source":["from sklearn import svm\n","from sklearn.model_selection import LeaveOneOut \n","#Create a svm Classifier\n","#model = svm.SVC(kernel='linear',cv=LeaveOneOut(), verbosity=2, n_jobs=8) # Linear Kernel\n","model = svm.SVC(kernel='linear')\n","##tpot = TPOTClassifier(generations=100, population_size=100, cv=LeaveOneOut(), verbosity=2, n_jobs=8)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i9pG21RgBJDA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IaJjuTQuBJDG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O8V-S9UcBJDJ","colab_type":"code","colab":{}},"source":["'''\n","from sklearn.model_selection import LeaveOneOut \n","loo = LeaveOneOut()\n","ytests = []\n","ypreds = []\n","\n","for train_idx, test_idx in loo.split(data_avn_fan):\n","    X_train, X_test = X_array[train_idx], X_array[test_idx] #requires arrays\n","    y_train, y_test = y_array[train_idx], y_array[test_idx]\n","    \n","    model = LinearRegression()\n","    model.fit(X = X_train, y = y_train) \n","    y_pred = model.predict(X_test)\n","        \n","    # there is only one y-test and y-pred per iteration over the loo.split, \n","    # so to get a proper graph, we append them to respective lists.\n","        \n","    ytests += list(y_test)\n","    ypreds += list(y_pred)\n","        \n","rr = metrics.r2_score(ytests, ypreds)\n","ms_error = metrics.mean_squared_error(ytests, ypreds)\n","        \n","print(\"Leave One Out Cross Validation\")\n","print(\"R^2: {:.5f}%, MSE: {:.5f}\".format(rr*100, ms_error))\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_bTDk5K6BJDL","colab_type":"text"},"source":["# GRID SEARCH hyperparameter tuning"]},{"cell_type":"code","metadata":{"id":"ib4Us6t_BJDM","colab_type":"code","colab":{},"outputId":"2ff9caa5-aaca-47b7-95a0-5a81dffdc652"},"source":["'''\n","from sklearn import svm\n","from sklearn.model_selection import LeaveOneOut \n","import numpy as np\n","from sklearn.grid_search import GridSearchCV\n","from sklearn import datasets, svm\n","import matplotlib.pyplot as plt\n","\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error\n","\n","from sklearn.metrics import accuracy_score\n","\n","parameter_candidates = [\n","  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n","  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n","]\n","# Create a classifier object with the classifier and parameter candidates\n","model = GridSearchCV(estimator=svm.SVR(), param_grid=parameter_candidates, n_jobs=-1)\n","\n","model.fit(data_avn_fan, target_1col)\n","#mean absolute value for training data\n","##data = train[target]\n","true_target = target_1col\n","##predict =  model.predict(train[features])\n","predict =  model.predict(data_avn_fan)\n","\n","\n","\n","'''\n"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"cannot import name 'mean_square_error'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-9dea3adc8eeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_square_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'mean_square_error'"]}]},{"cell_type":"markdown","metadata":{"id":"WPtFNfQRBJDO","colab_type":"text"},"source":["# GENERAL MODEL fit & Training cell"]},{"cell_type":"code","metadata":{"id":"1ZR2tgAKBJDP","colab_type":"code","colab":{},"outputId":"26c28dc4-d923-46c3-ca88-dd603bfd1afb"},"source":["'''\n","x_train =  #-----------------------------------------------\n","\n","x_test = \n","\n","y_train_true = \n","y_test_pred\n","y_test_true =  #----------------------------------------\n","'''\n","model.fit(x_train, y_train_true.values.ravel()) ###########################################\n","\n","#mean absolute value for training data\n","##data = train[target]\n","\n"," \n"," \n","##predict =  model.predict(train[features])\n","y_train_pred =  model.predict(x_train)  #--------------------------------------------------\n","\n","\n","\n","print (y_train_true.values.ravel(),y_train_pred)\n","\n","y_test_pred = model.predict(x_test)\n","\n","print(y_test_true.values.ravel(), y_test_pred)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[2 2 1 2 1 2 1 3 2 3 3 1 2 2 1 3 1 1 1 1 3 1 3 3 1 3 3 1 3 3 2 3 3 3 3 2 1\n"," 2 3 1 3 3 3 1 3 3 2 3 1 1 3 2 3 3 3 1 2 1 1 3 2 2 3 2 3 2 3 2 1 2 3 3 2 2\n"," 1 2 3 2 3 1 3 1 2 1 3 3 1 1 2 2 3 1 1 1 3 2 2 1 1 1 3 2 1 1 1 2 3 3 1 1 2\n"," 3 2 1 1 2 1 1] [3 2 3 2 1 2 3 3 2 3 3 2 1 3 1 1 1 3 1 1 1 1 3 3 1 3 3 3 1 3 1 1 3 3 3 1 1\n"," 1 3 1 3 3 3 1 1 3 3 3 1 1 1 1 2 3 3 1 1 1 1 3 2 2 3 2 3 3 3 1 1 2 1 2 1 1\n"," 1 3 3 1 3 2 3 3 3 1 2 3 1 1 1 1 3 1 1 1 3 1 3 3 2 2 3 3 1 1 3 3 3 3 1 1 1\n"," 2 2 1 1 3 1 1]\n","[1 1 3 2 2 2 1 1 1 1 3 1 2 3] [3 2 2 1 2 3 2 1 1 2 3 1 1 1]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iF9j7ub8BJDR","colab_type":"code","colab":{},"outputId":"3af18610-3055-4c57-a5dd-1ce9d4f0f18b"},"source":["accuracy = r2_score(y_test_true, y_test_pred)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'r2_score' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-8858143ba600>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'r2_score' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"6TLMRlQvBJDU","colab_type":"text"},"source":["# accuracy cell "]},{"cell_type":"code","metadata":{"id":"diGevuPnBJDV","colab_type":"code","colab":{},"outputId":"c57a2cdb-f93c-4301-dc73-5a743a1bcd50"},"source":["from sklearn import metrics\n","print(\"Accuracy:\",metrics.accuracy_score(y_test_true, y_test_pred))\n","\n","print(\"Train Accuracy:\",metrics.accuracy_score(y_train_true, y_train_pred))\n","\n","\n","from sklearn.metrics import confusion_matrix \n","from sklearn.metrics import accuracy_score \n","from sklearn.metrics import classification_report \n","\n","results = confusion_matrix(y_test_true, y_test_pred)\n","print ('Confusion Matrix :')\n","print(results) \n","print ('Accuracy Score :',accuracy_score(y_test_true, y_test_pred) ) \n","print ('Report : ')\n","print (classification_report(y_test_true, y_test_pred) )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy: 0.357142857143\n","Train Accuracy: 0.610169491525\n","Confusion Matrix :\n","[[3 3 1]\n"," [2 1 1]\n"," [1 1 1]]\n","Accuracy Score : 0.357142857143\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.50      0.43      0.46         7\n","          2       0.20      0.25      0.22         4\n","          3       0.33      0.33      0.33         3\n","\n","avg / total       0.38      0.36      0.37        14\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_XbyqYtKBJDX","colab_type":"text"},"source":["# K-fold cross validation training & score"]},{"cell_type":"code","metadata":{"id":"h1hco65cBJDY","colab_type":"code","colab":{},"outputId":"bc2aecd0-5ff7-4fb6-cd08-1aa39e7f8de0"},"source":["from sklearn.model_selection import cross_val_score\n","#scores = cross_val_score(model , X = x_train , y = y_train_true , cv = x_train.shape[0]) \n","scores = cross_val_score(model , X = x_train , y = y_train_true.values.ravel() , cv = 30) \n","print (scores)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[ 0.33333333  0.          0.5         0.6         0.4         0.4         0.8\n","  0.6         0.6         0.4         0.8         0.2         1.          0.\n","  0.33333333  1.          0.33333333  0.          0.          0.33333333\n","  0.33333333  0.66666667  0.33333333  0.33333333  0.66666667  0.66666667\n","  0.33333333  0.33333333  1.          0.33333333]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cuIBbQwwBJDe","colab_type":"text"},"source":["# LEAVE ONE OUT USING SVM (named as model) 100%  data ONLY AVN & FAN"]},{"cell_type":"code","metadata":{"id":"VlaNpTotBJDf","colab_type":"code","colab":{},"outputId":"11826ee1-eb54-4f63-a513-8f078fbb4c74"},"source":["parameter_candidates = [\n","  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n","  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n","]\n","# Create a classifier object with the classifier and parameter candidates\n","model = GridSearchCV(estimator=svm.SVC(), param_grid=parameter_candidates, n_jobs=-1)\n","\n","\n","\n","from sklearn.model_selection import LeaveOneOut ########LEAVE ONE OUT\n","import numpy as np\n","#x = np.array([[1, 2], [3, 4]])\n","x_train = data_avn_fan.iloc[:,1:17] #----------------\n","y_train = data_avn_fan.iloc[:,[0]]\n","\n","\n","x = np.array(x_train)\n","y = np.array(y_train.values.ravel())\n","loo = LeaveOneOut()\n","loo.get_n_splits(x)\n","# x_train mane whole data nea dorkar ekhane\n","for train_index, test_index in loo.split(x):\n","        #print(\"train:\", train_index, \"validation:\", test_index)\n","        x_train, x_test = x[train_index], x[test_index]\n","        y_train, y_test = y[train_index], y[test_index]\n","        \n","        \n","        model.fit(x_train, y_train.ravel())\n","        y_train_pred =  model.predict(x_train)  #--------------------------------------------------\n","        #print (y_train_true.values.ravel(),y_train_pred)\n","\n","        #y_test_pred = model.predict(x_test)        \n","#model.fit(x_train, y_train_true.values.ravel()) ###########################################\n","\n","print('Best C:',model.best_estimator_.C) \n","print('Best Kernel:',model.best_estimator_.kernel)\n","print('Best Gamma:',model.best_estimator_.gamma)\n","\n","from sklearn import metrics\n","from sklearn.metrics import confusion_matrix \n","from sklearn.metrics import accuracy_score \n","from sklearn.metrics import classification_report \n","\n","print(\"Train Accuracy:\",metrics.accuracy_score(y_train, y_train_pred))\n","\n","results = confusion_matrix(y_train, y_train_pred)\n","print ('Confusion Matrix :')\n","print(results) \n","print ('Accuracy Score :',accuracy_score(y_train, y_train_pred) ) \n","print ('Report : ')\n","print (classification_report(y_train, y_train_pred) )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train Accuracy: 0.610687022901\n","Confusion Matrix :\n","[[38  3  8]\n"," [16  9 11]\n"," [ 8  5 33]]\n","Accuracy Score : 0.610687022901\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.61      0.78      0.68        49\n","          2       0.53      0.25      0.34        36\n","          3       0.63      0.72      0.67        46\n","\n","avg / total       0.60      0.61      0.59       131\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SYytK39OBJDl","colab_type":"text"},"source":["# Same model 90% random data"]},{"cell_type":"code","metadata":{"id":"fpt-K6PvBJDm","colab_type":"code","colab":{},"outputId":"2138fb1b-7b14-4a36-f87d-828ed727c968"},"source":["parameter_candidates = [\n","  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n","  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n","]\n","# Create a classifier object with the classifier and parameter candidates\n","model = GridSearchCV(estimator=svm.SVC(), param_grid=parameter_candidates, n_jobs=-1)\n","\n","\n","\n","from sklearn.model_selection import LeaveOneOut ########LEAVE ONE OUT\n","import numpy as np\n","#x = np.array([[1, 2], [3, 4]])\n","#x_train = data_avn_fan_op.iloc[:,[0]] #----------------\n","#y_train = data_avn_fan_op.iloc[:,[0]]\n","\n","\n","x = np.array(x_train)\n","y = np.array(y_train.values.ravel())\n","loo = LeaveOneOut()\n","loo.get_n_splits(x)\n","# x_train mane whole data nea dorkar ekhane\n","for train_index, test_index in loo.split(x):\n","        #print(\"train:\", train_index, \"validation:\", test_index)\n","        x_train, x_test = x[train_index], x[test_index]\n","        y_train, y_test = y[train_index], y[test_index]\n","        \n","        \n","        model.fit(x_train, y_train.ravel())\n","        y_train_pred =  model.predict(x_train)  #--------------------------------------------------\n","        #print (y_train_true.values.ravel(),y_train_pred)\n","\n","        #y_test_pred = model.predict(x_test)\n","\n","        \n","#model.fit(x_train, y_train_true.values.ravel()) ###########################################\n","\n","#mean absolute value for training data\n","##data = train[target]\n","\n","#print(y_test_true.values.ravel(), y_test_pred)\n","\n","\n","from sklearn import metrics\n","\n","print(\"Train Accuracy:\",metrics.accuracy_score(y_train, y_train_pred))\n","\n","\n","from sklearn.metrics import confusion_matrix \n","from sklearn.metrics import accuracy_score \n","from sklearn.metrics import classification_report \n","\n","results = confusion_matrix(y_train, y_train_pred)\n","print ('Confusion Matrix :')\n","print(results) \n","print ('Accuracy Score :',accuracy_score(y_train, y_train_pred) ) \n","print ('Report : ')\n","print (classification_report(y_train, y_train_pred) )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train Accuracy: 1.0\n","Confusion Matrix :\n","[[49  0  0]\n"," [ 0 36  0]\n"," [ 0  0 46]]\n","Accuracy Score : 1.0\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       1.00      1.00      1.00        49\n","          2       1.00      1.00      1.00        36\n","          3       1.00      1.00      1.00        46\n","\n","avg / total       1.00      1.00      1.00       131\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LRZjHVn-BJDp","colab_type":"text"},"source":["# Random forest ----leave one out & AVN_FAN"]},{"cell_type":"code","metadata":{"id":"qicTxnitBJDp","colab_type":"code","colab":{},"outputId":"a4868891-5a42-4f97-98ee-b474f6c0f0a4"},"source":["#Import Random Forest Model\n","from sklearn.ensemble import RandomForestClassifier\n","\n","clf=RandomForestClassifier(n_estimators=400)\n","model = clf\n","\n","#clf.fit(x_train,y_train_true)\n","#y_test_pred=clf.predict(x_test)\n","#x_train = data_avn_fan.iloc[:,1:17]\n","x_train = data_avn_fan_op.iloc[:,1:22] #----------------\n","y_train = data_avn_fan_op.iloc[:,[0]]\n","\n","\n","x = np.array(x_train)\n","y = np.array(y_train.values.ravel())\n","loo = LeaveOneOut()\n","loo.get_n_splits(x)\n","for train_index, test_index in loo.split(x):\n","        #print(\"train:\", train_index, \"validation:\", test_index)\n","        x_train, x_test = x[train_index], x[test_index]\n","        y_train, y_test = y[train_index], y[test_index]\n","        \n","        \n","        model.fit(x_train, y_train.ravel())\n","        y_train_pred =  model.predict(x_train)  #--------------------------------------------------\n","        #print (y_train_true.values.ravel(),y_train_pred)\n","\n","        #y_test_pred = model.predict(x_test)        \n","#model.fit(x_train, y_train_true.values.ravel()) ###########################################\n","\n","from sklearn import metrics\n","from sklearn.metrics import confusion_matrix \n","from sklearn.metrics import accuracy_score \n","from sklearn.metrics import classification_report \n","\n","print(\"Train Accuracy:\",metrics.accuracy_score(y_train, y_train_pred))\n","\n","results = confusion_matrix(y_train, y_train_pred)\n","print ('Confusion Matrix :')\n","print(results) \n","print ('Accuracy Score :',accuracy_score(y_train, y_train_pred) ) \n","print ('Report : ')\n","print (classification_report(y_train, y_train_pred) )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train Accuracy: 0.908396946565\n","Confusion Matrix :\n","[[47  1  1]\n"," [ 4 31  1]\n"," [ 5  0 41]]\n","Accuracy Score : 0.908396946565\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.84      0.96      0.90        49\n","          2       0.97      0.86      0.91        36\n","          3       0.95      0.89      0.92        46\n","\n","avg / total       0.91      0.91      0.91       131\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RPySTW0PBJDt","colab_type":"text"},"source":["AVN & FAN - Random forest-400\n","Train Accuracy: 0.862595419847\n","Confusion Matrix :\n","[[45  0  4]\n"," [ 7 28  1]\n"," [ 4  2 40]]\n","Accuracy Score : 0.862595419847\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.80      0.92      0.86        49\n","          2       0.93      0.78      0.85        36\n","          3       0.89      0.87      0.88        46\n","\n","avg / total       0.87      0.86      0.86       131"]},{"cell_type":"markdown","metadata":{"id":"HvzyO6_RBJDu","colab_type":"text"},"source":["AVN & FAN & OP- Random forest-400\n","Accuracy: 0.908396946565\n","Confusion Matrix :\n","[[47  1  1]\n"," [ 4 31  1]\n"," [ 5  0 41]]\n","Accuracy Score : 0.908396946565\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.84      0.96      0.90        49\n","          2       0.97      0.86      0.91        36\n","          3       0.95      0.89      0.92        46\n","\n","avg / total       0.91      0.91      0.91       131"]},{"cell_type":"markdown","metadata":{"id":"SZUcYxwcBJDv","colab_type":"text"},"source":["# ERROR for REGression"]},{"cell_type":"code","metadata":{"id":"nu-ACcnkBJDx","colab_type":"code","colab":{}},"source":["\n","\n","\n","test_data_error = mean_absolute_error(y_test_true, y_test_pred)\n","accuracy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aQEaz6rCBJD0","colab_type":"code","colab":{},"outputId":"6611ea6e-ef96-425a-c31c-37813b8deb66"},"source":["#define model I am using\n","model = LinearRegression()\n","#training process\n","##model.fit(train[features], train[target])\n","from sklearn.metrics import f1_score\n","\n","model.fit(data_avn, target_1col)\n","#mean absolute value for training data\n","##data = train[target]\n","true_target = target_1col\n","##predict =  model.predict(train[features])\n","predict =  model.predict(data_avn)\n","\n","\n","training_error = mean_absolute_error(true_target, predict)\n","accuracy = r2_score(true_target, predict)\n","#accuracy = f1_score(true_target, predict, average='micro')\n","print(predict)\n","accuracy\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[  2799.4262873 ]\n"," [  2833.22335692]\n"," [  2492.58545066]\n"," [  2551.87960068]\n"," [  2000.29881734]\n"," [  2124.05002439]\n"," [  2365.65288887]\n"," [  2001.82331314]\n"," [  5050.11742108]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [ 13033.93275207]\n"," [  2688.02791551]\n"," [  3862.24907869]\n"," [  2365.65288887]\n"," [  2336.39627142]\n"," [  2773.44160075]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [  1526.43521463]\n"," [  1286.09171366]\n"," [  2034.09588696]\n"," [  7713.61507356]\n"," [  1873.36625554]\n"," [  3045.56960396]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [  1032.22659007]\n"," [  6963.05424183]\n"," [  2619.51801246]\n"," [  1873.36625554]\n"," [  2709.47214988]\n"," [  3975.29906205]\n"," [  1873.36625554]\n"," [  2463.32883322]\n"," [  2828.68290475]\n"," [  2336.39627142]\n"," [  2799.4262873 ]\n"," [  5239.91840605]\n"," [  1661.02000851]\n"," [  2364.06560477]\n"," [  1873.36625554]\n"," [  3484.2580694 ]\n"," [  2000.29881734]\n"," [  3987.65714468]\n"," [  3387.98549501]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [  7222.13449587]\n"," [  3062.46813877]\n"," [  4896.28629751]\n"," [   258.68106384]\n"," [  1873.36625554]\n"," [  2336.39627142]\n"," [  3997.12482753]\n"," [  2000.29881734]\n"," [  2824.04662904]\n"," [  1873.36625554]\n"," [  2336.39627142]\n"," [  1873.36625554]\n"," [  2795.37390671]\n"," [  1924.06185998]\n"," [  1873.36625554]\n"," [  2799.4262873 ]\n"," [ 10368.40054348]\n"," [  2336.39627142]\n"," [  2000.29881734]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [  1755.67999648]\n"," [  1873.36625554]\n"," [  1032.22659007]\n"," [  1873.36625554]\n"," [  6247.81596131]\n"," [  1873.36625554]\n"," [  5057.32994471]\n"," [  1873.36625554]\n"," [  3044.166234  ]\n"," [  4178.33621806]\n"," [  2119.50957221]\n"," [  4844.71395442]\n"," [  1873.36625554]\n"," [   592.22963183]\n"," [  2000.29881734]\n"," [  2000.29881734]\n"," [  1873.36625554]\n"," [  5469.1631879 ]\n"," [  2365.65288887]\n"," [  1873.36625554]\n"," [   191.08692459]\n"," [  2984.87208399]\n"," [  1873.36625554]\n"," [  3997.12482753]\n"," [  2136.40810702]\n"," [  2336.39627142]\n"," [  1873.36625554]\n"," [  1644.1214737 ]\n"," [  3044.166234  ]\n"," [  5297.78523354]\n"," [  3053.29141089]\n"," [  1873.36625554]\n"," [  2218.71001236]\n"," [  2799.4262873 ]\n"," [  1873.36625554]\n"," [  1897.98659728]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [  3754.7429365 ]\n"," [  2246.442134  ]\n"," [  1873.36625554]\n"," [  1897.98659728]\n"," [  2127.23137913]\n"," [  5239.91840605]]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.39671025891021217"]},"metadata":{"tags":[]},"execution_count":83}]},{"cell_type":"code","metadata":{"id":"UYESlc2zBJD2","colab_type":"code","colab":{},"outputId":"e44ed9cf-e4ab-4f3c-f5b5-a73a91ce23ff"},"source":["#define model I am using\n","model = LinearRegression()\n","#training process\n","##model.fit(train[features], train[target])\n","\n","\n","model.fit(data_avn_fan, target_1col)\n","#mean absolute value for training data\n","##data = train[target]\n","true_target = target_1col\n","##predict =  model.predict(train[features])\n","predict =  model.predict(data_avn_fan)\n","\n","\n","training_error = mean_absolute_error(true_target, predict)\n","accuracy2 = r2_score(true_target, predict)\n","\n","accuracy2"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.46434284014780314"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"code","metadata":{"id":"BdF5S_wqBJD4","colab_type":"code","colab":{},"outputId":"1b4ab3e0-9b22-47b8-847b-d09464f6edb4"},"source":["#mean absolute value for test data\n","\n","##test_data = test[target]\n","test_data = test.iloc[:,[1]]\n","test_data = test['wml']\n","##predict_test = model.predict(test[features])\n","test_data_avn=test.iloc[:,[12,13,14,15,16,17,30,31,32,33,34,35]]\n","test_data_fan=test.iloc[:,[18,19,20,21,22,23, 36,37,38,39,40,41]]\n","\n","predict_test = model.predict(test_data_avn)\n","test_data_error = mean_absolute_error(test_data, predict_test)\n","accuracy"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"shapes (14,12) and (24,1) not aligned: 12 (dim 1) != 24 (dim 0)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-0299c309e104>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtest_data_fan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m19\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m36\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m37\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m38\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m39\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m41\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpredict_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data_avn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mtest_data_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[0;32mC:\\Users\\Public\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[0;32mC:\\Users\\Public\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m--> 253\u001b[0;31m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[0;32mC:\\Users\\Public\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mfast_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: shapes (14,12) and (24,1) not aligned: 12 (dim 1) != 24 (dim 0)"]}]},{"cell_type":"code","metadata":{"id":"vg0p2EYIBJD6","colab_type":"code","colab":{},"outputId":"17f8f3e1-18a8-4e94-efe7-0baccd034503"},"source":["#we need some metric to measure the accuracy of our regression model\n","from sklearn.metrics import r2_score\n","#on training data\n","true_value = data\n","predicted_val =  model.predict(data_avn)\n","accuracy = r2_score(true_value, predicted_val)\n","print(accuracy)\n","#on test data\n","true_value2 = test_data\n","predicted_val2 =  model.predict(test_data_avn)\n","accuracy3 = r2_score(true_value2, predicted_val2)\n","print(accuracy2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.128221131561\n","0.130647591078\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"91MY7fQLBJD9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}