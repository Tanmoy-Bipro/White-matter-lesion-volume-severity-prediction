{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"myenv","language":"python","name":"myenv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"},"colab":{"name":"WML_CSV_all 3_latest_v2.ipynb","version":"0.3.2","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"pVIb80OZZD7b","colab_type":"code","colab":{},"outputId":"c2afec5a-561f-4baf-c4ad-42b2345e9de5"},"source":["\n","import pandas as pd\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import accuracy_score\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import accuracy_score\n","from sklearn.grid_search import GridSearchCV\n","from sklearn import datasets, svm\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import LeaveOneOut\n","#df = pd.read_csv('wml_data.csv', header = 0)\n","#df = pd.read_csv('wml_avn_fan_op.csv', header = 0)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["C:\\Users\\Public\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n","  \"This module will be removed in 0.20.\", DeprecationWarning)\n","C:\\Users\\Public\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n","  DeprecationWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"AsYDAlMcZD7h","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wDKglp8IZD7k","colab_type":"code","colab":{},"outputId":"02c245c8-0b4c-4987-872c-6dcabb0e8055"},"source":["#multivariate linear regression NEW BLOCK \n","#80/20 split- 20% training data\n","\n","#train, test = train_test_split(fifa_dataset, test_size=0.2)  // fifa_dataset here is a panda dataframe\n","\n","\n","\n","data_avn = pd.read_csv('wml_avn_label.csv', header = 0)\n","\n","data_fan = pd.read_csv('wml_fan_label.csv', header = 0)\n","\n","data_avn_fan = pd.read_csv('wml_avn_fan_label.csv', header = 0)\n","\n","data_avn_fan_op = pd.read_csv('wml_avn_fan_op_label.csv', header = 0)\n","\n","data_op = pd.read_csv('wml_op_label.csv', header = 0)\n","#label = pd.read_csv('wml_label.csv', header = 0)\n","\n","\n","\n","\n","\n","# for avn_fan_op\n","df2 = data_avn_fan_op  ##############################################################################\n","\n","train, test = train_test_split(df2, test_size=0.1)\n","\n","y_train_true = train.iloc[:,[0]]\n","\n","y_test_true = test.iloc[:,[0]]\n","\n","#x_train = train.iloc[:,1:22] #- Except OP mean median std----------------------------------------------\n","x_train = train.iloc[:,1:25]\n","x_test = test.iloc[:,1: 25]\n","\n","print( x_train , y_train_true)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["     0       0.1  0.2      0.3       0.4  0.5      0.6   1  0.7  1.1  ...   \\\n","79   2  0.416670    0  0.79296  0.916670  0.0  1.56430   3    4    1  ...    \n","110  2  0.333330    0  0.65134  0.166670  0.0  0.57735   4    2    4  ...    \n","95   0  0.000000    0  0.00000  0.500000  0.0  0.79772   1    2    6  ...    \n","41   2  0.166670    0  0.57735  0.583330  0.0  0.90034   3    2    2  ...    \n","28   1  0.083333    0  0.28868  0.833330  0.0  1.02990   1    2    1  ...    \n","58   0  0.000000    0  0.00000  0.333330  0.0  0.77850   1    2    2  ...    \n","4    0  0.000000    0  0.00000  0.166670  0.0  0.57735   1    2   11  ...    \n","82   2  0.166670    0  0.57735  0.750000  0.0  1.28810   3    4    5  ...    \n","22   1  0.083333    0  0.28868  0.166670  0.0  0.57735   4    2    9  ...    \n","124  0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1  ...    \n","83   3  0.916670    0  1.16450  0.166670  0.0  0.57735   4    2    9  ...    \n","85   1  0.083333    0  0.28868  0.666670  0.0  1.23090  12    4   12  ...    \n","106  0  0.000000    0  0.00000  0.333330  0.0  0.65134   1    2    4  ...    \n","51   0  0.000000    0  0.00000  0.166670  0.0  0.57735   1    2    9  ...    \n","53   0  0.000000    0  0.00000  0.166670  0.0  0.57735   1    2    9  ...    \n","6    2  0.250000    0  0.62158  0.000000  0.0  0.00000   4    0    1  ...    \n","113  1  0.083333    0  0.28868  0.000000  0.0  0.00000   4    0    1  ...    \n","8    1  0.083333    0  0.28868  0.000000  0.0  0.00000   5    0    1  ...    \n","2    0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1  ...    \n","81   2  0.583330    0  0.79296  0.166670  0.0  0.57735   9    2    4  ...    \n","131  0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1  ...    \n","104  2  0.166670    0  0.57735  0.166670  0.0  0.38925   4    1    3  ...    \n","107  0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1  ...    \n","10   0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1  ...    \n","90   4  0.416670    0  1.16450  0.333330  0.0  0.77850   4    2    6  ...    \n","116  0  0.000000    0  0.00000  0.083333  0.0  0.28868   1    1   11  ...    \n","55   1  0.083333    0  0.28868  2.416700  3.0  1.78160   3    4    2  ...    \n","130  1  0.083333    0  0.28868  0.000000  0.0  0.00000   3    0    1  ...    \n","69   0  0.000000    0  0.00000  0.083333  0.0  0.28868   1    1   11  ...    \n","46   0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1  ...    \n","..  ..       ...  ...      ...       ...  ...      ...  ..  ...  ...  ...    \n","93   2  0.166670    0  0.57735  0.416670  0.0  0.79296   4    2    5  ...    \n","99   2  0.166670    0  0.57735  0.333330  0.0  0.77850   5    2    3  ...    \n","19   4  1.000000    0  1.80910  0.000000  0.0  0.00000   8    0    1  ...    \n","68   1  0.083333    0  0.28868  0.083333  0.0  0.28868  12    1    8  ...    \n","29   0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1  ...    \n","59   1  0.083333    0  0.28868  0.083333  0.0  0.28868   4    1   10  ...    \n","102  1  0.083333    0  0.28868  0.000000  0.0  0.00000   3    0    1  ...    \n","75   2  0.500000    0  0.90453  1.333300  1.5  1.15470   3    3    9  ...    \n","123  2  0.166670    0  0.57735  0.000000  0.0  0.00000   4    0    1  ...    \n","47   0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1  ...    \n","56   4  1.083300    0  1.56430  0.166670  0.0  0.57735   9    2    9  ...    \n","17   2  0.416670    0  0.79296  0.000000  0.0  0.00000   5    0    1  ...    \n","89   4  0.833330    0  1.58590  0.333330  0.0  0.77850   9    2    4  ...    \n","120  1  0.083333    0  0.28868  0.083333  0.0  0.28868   6    1    8  ...    \n","35   2  0.250000    0  0.62158  0.000000  0.0  0.00000   2    0    1  ...    \n","117  0  0.000000    0  0.00000  0.083333  0.0  0.28868   1    1    3  ...    \n","11   2  1.000000    1  1.04450  0.000000  0.0  0.00000   4    0    1  ...    \n","80   2  0.750000    0  0.96531  0.000000  0.0  0.00000   4    0    1  ...    \n","64   1  0.083333    0  0.28868  0.000000  0.0  0.00000   4    0    1  ...    \n","39   0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1  ...    \n","48   1  0.166670    0  0.38925  0.250000  0.0  0.62158   3    2    3  ...    \n","125  0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1  ...    \n","21   1  0.083333    0  0.28868  0.166670  0.0  0.57735   3    2    3  ...    \n","23   0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1  ...    \n","128  1  0.083333    0  0.28868  0.083333  0.0  0.28868   3    1    9  ...    \n","92   2  0.333330    0  0.65134  0.333330  0.0  0.65134   3    2    6  ...    \n","109  1  0.166670    0  0.38925  0.000000  0.0  0.00000   3    0    1  ...    \n","91   2  0.666670    0  0.98473  0.000000  0.0  0.00000   8    0    1  ...    \n","31   0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1  ...    \n","112  0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1  ...    \n","\n","     1.2  0.12  0.13  0.14  0.15  0.16  0.17  0.18  0.19  0.20  \n","79     1     5     0     8     3     4     0     5    11     4  \n","110    3     4     0     2     0     2     0     4     2     2  \n","95     5     0     0     2     4     2     2     0     6     4  \n","41     9     2     0     7     0     6     4     2     7    10  \n","28     1     1     0     8     2     6     2     1    10     8  \n","58     1     0     0     4     0     4     0     0     4     4  \n","4      1     0     0     0     2     0     0     0     2     0  \n","82     4     2     0     8     1     6     0     2     9     6  \n","22     1     1     0     0     2     0     0     1     2     0  \n","124    1     0     0     0     0     0     0     0     0     0  \n","83     1     3     8     0     2     0     0    11     2     0  \n","85     3     0     1     4     4     3     2     1     8     5  \n","106    3     0     0     4     0     4     2     0     4     6  \n","51     8     0     0     0     2     0     1     0     2     1  \n","53    10     0     0     0     2     0     2     0     2     2  \n","6      1     2     1     0     0     0     0     3     0     0  \n","113    8     1     0     0     0     0     4     1     0     4  \n","8      1     1     0     0     0     0     0     1     0     0  \n","2      1     0     0     0     0     0     0     0     0     0  \n","81     3     3     4     2     0     2     2     7     2     4  \n","131    1     0     0     0     0     0     0     0     0     0  \n","104    2     2     0     1     1     1     0     2     2     1  \n","107    1     0     0     0     0     0     0     0     0     0  \n","10     1     0     0     0     0     0     0     0     0     0  \n","90     5     5     0     2     2     2     0     5     4     2  \n","116    9     0     0     0     1     0     1     0     1     1  \n","55     1     1     0    21     8    20     0     1    29    20  \n","130    1     1     0     0     0     0     0     1     0     0  \n","69     8     0     0     0     1     0     2     0     1     2  \n","46     1     0     0     0     0     0     0     0     0     0  \n","..   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n","93     4     2     0     2     3     2     1     2     5     3  \n","99     2     2     0     2     2     2     0     2     4     2  \n","19     1     0    12     0     0     0     0    12     0     0  \n","68     8     0     1     0     1     0     1     1     1     1  \n","29     1     0     0     0     0     0     0     0     0     0  \n","59     9     1     0     0     1     0     1     1     1     1  \n","102    1     1     0     0     0     0     0     1     0     0  \n","75     8     6     0     8     8     7    10     6    16    17  \n","123    1     2     0     0     0     0     0     2     0     0  \n","47     1     0     0     0     0     0     0     0     0     0  \n","56     6     1    12     0     2     2     4    13     2     6  \n","17     1     3     2     0     0     0     0     5     0     0  \n","89     3     2     8     4     0     4     0    10     4     4  \n","120    1     1     0     0     1     0     0     1     1     0  \n","35     1     3     0     0     0     0     0     3     0     0  \n","117    7     0     0     1     0     1     2     0     1     3  \n","11     1     2    10     0     0     0     0    12     0     0  \n","80     6     4     5     0     0     2     0     9     0     2  \n","64     1     1     0     0     0     0     0     1     0     0  \n","39     7     0     0     0     0     0     1     0     0     1  \n","48     2     1     1     2     1     2     1     2     3     3  \n","125    1     0     0     0     0     0     0     0     0     0  \n","21     2     1     0     2     0     2     0     1     2     2  \n","23     1     0     0     0     0     0     0     0     0     0  \n","128    1     1     0     0     1     0     0     1     1     0  \n","92     5     4     0     3     1     3     0     4     4     3  \n","109    1     2     0     0     0     0     0     2     0     0  \n","91     1     0     8     0     0     0     0     8     0     0  \n","31     6     0     0     0     0     2     0     0     0     2  \n","112    1     0     0     0     0     0     0     0     0     0  \n","\n","[118 rows x 24 columns]      2\n","79   2\n","110  2\n","95   1\n","41   2\n","28   1\n","58   2\n","4    2\n","82   2\n","22   2\n","124  1\n","83   1\n","85   2\n","106  1\n","51   2\n","53   2\n","6    2\n","113  1\n","8    1\n","2    2\n","81   2\n","131  2\n","104  2\n","107  1\n","10   1\n","90   2\n","116  1\n","55   1\n","130  1\n","69   1\n","46   2\n","..  ..\n","93   2\n","99   2\n","19   1\n","68   2\n","29   2\n","59   2\n","102  1\n","75   2\n","123  1\n","47   2\n","56   2\n","17   2\n","89   2\n","120  1\n","35   2\n","117  2\n","11   2\n","80   2\n","64   1\n","39   2\n","48   1\n","125  1\n","21   2\n","23   1\n","128  1\n","92   2\n","109  2\n","91   1\n","31   1\n","112  2\n","\n","[118 rows x 1 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y5BSOq3XZD7n","colab_type":"code","colab":{},"outputId":"01ba8982-da0a-464a-ad07-278214387942"},"source":["# for avn_fan\n","df2 = data_avn_fan  ##############################################################################\n","\n","train, test = train_test_split(df2, test_size=0.1)\n","\n","y_train_true = train.iloc[:,[0]]\n","\n","y_test_true = test.iloc[:,[0]]\n","\n","x_train = train.iloc[:,1:17] #-----------------------------------------------\n","\n","x_test = test.iloc[:,1: 17]\n","\n","print( x_train , y_train_true)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["     0       0.1  0.2      0.3       0.4  0.5      0.6   1  0.7  1.1  0.8  \\\n","18   2  0.250000    0  0.62158  0.166670  0.0  0.38925   9    1    4    0   \n","22   1  0.083333    0  0.28868  0.166670  0.0  0.57735   4    2    9    1   \n","71   0  0.000000    0  0.00000  0.416670  0.0  0.79296   1    2    1    0   \n","76   2  0.333330    0  0.77850  1.083300  0.0  1.78160   3    4    1    4   \n","44   1  0.083333    0  0.28868  0.000000  0.0  0.00000   3    0    1    1   \n","77   2  0.166670    0  0.57735  1.666700  2.0  1.66970  10    4    3    0   \n","21   1  0.083333    0  0.28868  0.166670  0.0  0.57735   3    2    3    1   \n","95   0  0.000000    0  0.00000  0.500000  0.0  0.79772   1    2    6    0   \n","38   2  0.250000    0  0.62158  0.416670  0.0  0.79296   4    2    4    3   \n","78   1  0.083333    0  0.28868  0.916670  0.0  1.56430   5    4    3    1   \n","29   0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1    0   \n","53   0  0.000000    0  0.00000  0.166670  0.0  0.57735   1    2    9    0   \n","20   1  0.166670    0  0.38925  0.166670  0.0  0.57735   8    2    6    0   \n","39   0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1    0   \n","81   2  0.583330    0  0.79296  0.166670  0.0  0.57735   9    2    4    3   \n","49   1  0.083333    0  0.28868  0.166670  0.0  0.57735   3    2    2    1   \n","101  0  0.000000    0  0.00000  0.083333  0.0  0.28868   1    1    8    0   \n","68   1  0.083333    0  0.28868  0.083333  0.0  0.28868  12    1    8    0   \n","57   2  0.666670    0  0.98473  0.333330  0.0  1.15470   1    4    4    4   \n","103  1  0.083333    0  0.28868  0.000000  0.0  0.00000   5    0    1    1   \n","102  1  0.083333    0  0.28868  0.000000  0.0  0.00000   3    0    1    1   \n","3    4  0.333330    0  1.15470  0.000000  0.0  0.00000   5    0    1    4   \n","96   1  0.083333    0  0.28868  0.250000  0.0  0.62158   4    2    8    1   \n","63   0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1    0   \n","12   0  0.000000    0  0.00000  0.250000  0.0  0.62158   1    2    8    0   \n","128  1  0.083333    0  0.28868  0.083333  0.0  0.28868   3    1    9    1   \n","45   0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1    0   \n","55   1  0.083333    0  0.28868  2.416700  3.0  1.78160   3    4    2    1   \n","50   2  0.166670    0  0.57735  0.000000  0.0  0.00000   8    0    1    0   \n","99   2  0.166670    0  0.57735  0.333330  0.0  0.77850   5    2    3    2   \n","..  ..       ...  ...      ...       ...  ...      ...  ..  ...  ...  ...   \n","84   1  0.083333    0  0.28868  0.750000  0.0  0.96531   4    2    1    1   \n","67   2  0.333330    0  0.77850  0.416670  0.0  0.66856   3    2    3    4   \n","34   0  0.000000    0  0.00000  0.250000  0.0  0.62158   1    2    3    0   \n","115  1  0.083333    0  0.28868  0.000000  0.0  0.00000   4    0    1    1   \n","79   2  0.416670    0  0.79296  0.916670  0.0  1.56430   3    4    1    5   \n","120  1  0.083333    0  0.28868  0.083333  0.0  0.28868   6    1    8    1   \n","6    2  0.250000    0  0.62158  0.000000  0.0  0.00000   4    0    1    2   \n","108  0  0.000000    0  0.00000  0.166670  0.0  0.38925   1    1    9    0   \n","109  1  0.166670    0  0.38925  0.000000  0.0  0.00000   3    0    1    2   \n","116  0  0.000000    0  0.00000  0.083333  0.0  0.28868   1    1   11    0   \n","124  0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1    0   \n","16   0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1    0   \n","8    1  0.083333    0  0.28868  0.000000  0.0  0.00000   5    0    1    1   \n","72   1  0.083333    0  0.28868  0.166670  0.0  0.57735   3    2    9    1   \n","118  0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1    0   \n","15   1  0.083333    0  0.28868  0.083333  0.0  0.28868   1    1    5    1   \n","60   2  0.166670    0  0.57735  0.333330  0.0  0.77850   4    2    8    2   \n","117  0  0.000000    0  0.00000  0.083333  0.0  0.28868   1    1    3    0   \n","32   1  0.166670    0  0.38925  0.083333  0.0  0.28868   3    1    9    2   \n","125  0  0.000000    0  0.00000  0.000000  0.0  0.00000   1    0    1    0   \n","97   3  0.416670    0  0.90034  0.166670  0.0  0.57735   4    2    9    5   \n","73   4  0.583330    0  1.37900  1.750000  1.0  1.91290   4    4    1    7   \n","19   4  1.000000    0  1.80910  0.000000  0.0  0.00000   8    0    1    0   \n","94   2  0.250000    0  0.62158  0.166670  0.0  0.57735  12    2    9    1   \n","65   2  0.333330    0  0.65134  0.416670  0.0  0.79296   8    2    9    2   \n","98   0  0.000000    0  0.00000  0.250000  0.0  0.62158   1    2    9    0   \n","104  2  0.166670    0  0.57735  0.166670  0.0  0.38925   4    1    3    2   \n","85   1  0.083333    0  0.28868  0.666670  0.0  1.23090  12    4   12    0   \n","42   0  0.000000    0  0.00000  0.250000  0.0  0.62158   1    2    2    0   \n","28   1  0.083333    0  0.28868  0.833330  0.0  1.02990   1    2    1    1   \n","\n","     0.9  0.10  0.11  0.12  0.13  \n","18     3     1     1     3     2  \n","22     0     0     2     1     2  \n","71     0     4     1     0     5  \n","76     0     9     4     4    13  \n","44     0     0     0     1     0  \n","77     2    10    10     2    20  \n","21     0     2     0     1     2  \n","95     0     2     4     0     6  \n","38     0     2     3     3     5  \n","78     0     9     2     1    11  \n","29     0     0     0     0     0  \n","53     0     0     2     0     2  \n","20     2     2     0     2     2  \n","39     0     0     0     0     0  \n","81     4     2     0     7     2  \n","49     0     2     0     1     2  \n","101    0     0     1     0     1  \n","68     1     0     1     1     1  \n","57     4     4     0     8     4  \n","103    0     0     0     1     0  \n","102    0     0     0     1     0  \n","3      0     0     0     4     0  \n","96     0     0     3     1     3  \n","63     0     0     0     0     0  \n","12     0     0     3     0     3  \n","128    0     0     1     1     1  \n","45     0     0     0     0     0  \n","55     0    21     8     1    29  \n","50     2     0     0     2     0  \n","99     0     2     2     2     4  \n","..   ...   ...   ...   ...   ...  \n","84     0     4     5     1     9  \n","67     0     4     1     4     5  \n","34     0     3     0     0     3  \n","115    0     0     0     1     0  \n","79     0     8     3     5    11  \n","120    0     0     1     1     1  \n","6      1     0     0     3     0  \n","108    0     0     2     0     2  \n","109    0     0     0     2     0  \n","116    0     0     1     0     1  \n","124    0     0     0     0     0  \n","16     0     0     0     0     0  \n","8      0     0     0     1     0  \n","72     0     0     2     1     2  \n","118    0     0     0     0     0  \n","15     0     1     0     1     1  \n","60     0     0     4     2     4  \n","117    0     1     0     0     1  \n","32     0     0     1     2     1  \n","125    0     0     0     0     0  \n","97     0     0     2     5     2  \n","73     0    14     7     7    21  \n","19    12     0     0    12     0  \n","94     2     0     2     3     2  \n","65     2     0     5     4     5  \n","98     0     0     3     0     3  \n","104    0     1     1     2     2  \n","85     1     4     4     1     8  \n","42     0     3     0     0     3  \n","28     0     8     2     1    10  \n","\n","[118 rows x 16 columns]      3\n","18   3\n","22   2\n","71   2\n","76   1\n","44   1\n","77   1\n","21   2\n","95   1\n","38   3\n","78   3\n","29   2\n","53   2\n","20   3\n","39   2\n","81   3\n","49   2\n","101  2\n","68   2\n","57   3\n","103  3\n","102  1\n","3    3\n","96   3\n","63   1\n","12   1\n","128  1\n","45   1\n","55   1\n","50   3\n","99   3\n","..  ..\n","84   1\n","67   2\n","34   1\n","115  3\n","79   3\n","120  1\n","6    2\n","108  2\n","109  2\n","116  1\n","124  1\n","16   1\n","8    1\n","72   2\n","118  1\n","15   1\n","60   3\n","117  2\n","32   3\n","125  1\n","97   3\n","73   3\n","19   1\n","94   3\n","65   3\n","98   2\n","104  3\n","85   2\n","42   2\n","28   1\n","\n","[118 rows x 1 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YtcDuPMdZD7q","colab_type":"code","colab":{},"outputId":"133151e1-01c4-4212-a752-0540c204fccf"},"source":["# for avn\n","df2 = data_avn  ##############################################################################\n","\n","train, test = train_test_split(df2, test_size=0.1)\n","\n","y_train_true = train.iloc[:,[0]]\n","\n","y_test_true = test.iloc[:,[0]]\n","\n","x_train = train.iloc[:,1:8] #-----------------------------------------------\n","\n","x_test = test.iloc[:,1: 8]\n","\n","print( x_train , y_train_true)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["     0   1  0.1  0.2\n","127  0   1    0    0\n","93   2   4    2    0\n","124  0   1    0    0\n","0    0   1    0    0\n","73   4   4    7    0\n","57   2   1    4    4\n","1    0   1    0    0\n","37   0   1    0    0\n","96   1   4    1    0\n","90   4   4    5    0\n","125  0   1    0    0\n","83   3   4    3    8\n","19   4   8    0   12\n","65   2   8    2    2\n","101  0   1    0    0\n","50   2   8    0    2\n","106  0   1    0    0\n","69   0   1    0    0\n","17   2   5    3    2\n","97   3   4    5    0\n","100  2  10    0    2\n","112  0   1    0    0\n","78   1   5    1    0\n","109  1   3    2    0\n","80   2   4    4    5\n","16   0   1    0    0\n","9    2   9    0    2\n","79   2   3    5    0\n","31   0   1    0    0\n","4    0   1    0    0\n","..  ..  ..  ...  ...\n","8    1   5    1    0\n","95   0   1    0    0\n","21   1   3    1    0\n","39   0   1    0    0\n","77   2  10    0    2\n","89   4   9    2    8\n","122  1   6    1    0\n","42   0   1    0    0\n","32   1   3    2    0\n","74   4   9    4   12\n","28   1   1    1    0\n","20   1   8    0    2\n","35   2   2    3    0\n","82   2   3    2    0\n","75   2   3    6    0\n","115  1   4    1    0\n","54   0   1    0    0\n","126  0   1    0    0\n","47   0   1    0    0\n","119  0   1    0    0\n","113  1   4    1    0\n","103  1   5    1    0\n","71   0   1    0    0\n","6    2   4    2    1\n","129  1   4    1    0\n","29   0   1    0    0\n","62   0   1    0    0\n","36   0   1    0    0\n","30   4   8    1    6\n","86   1   4    1    0\n","\n","[118 rows x 4 columns]      3\n","127  1\n","93   3\n","124  1\n","0    3\n","73   3\n","57   3\n","1    3\n","37   1\n","96   3\n","90   3\n","125  1\n","83   1\n","19   1\n","65   3\n","101  2\n","50   3\n","106  1\n","69   1\n","17   3\n","97   3\n","100  2\n","112  3\n","78   3\n","109  2\n","80   2\n","16   1\n","9    3\n","79   3\n","31   1\n","4    2\n","..  ..\n","8    1\n","95   1\n","21   2\n","39   2\n","77   1\n","89   3\n","122  3\n","42   2\n","32   3\n","74   3\n","28   1\n","20   3\n","35   3\n","82   2\n","75   3\n","115  3\n","54   3\n","126  1\n","47   2\n","119  2\n","113  1\n","103  3\n","71   2\n","6    2\n","129  2\n","29   2\n","62   1\n","36   2\n","30   2\n","86   3\n","\n","[118 rows x 1 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0qYEy26LZD7t","colab_type":"code","colab":{}},"source":["# for fan\n","df2 = data_fan  ##############################################################################\n","\n","train, test = train_test_split(df2, test_size=0.1)\n","\n","y_train_true = train.iloc[:,[0]]\n","\n","y_test_true = test.iloc[:,[0]]\n","\n","x_train = train.iloc[:,1:8] #-----------------------------------------------\n","\n","x_test = test.iloc[:,1: 8]\n","\n","print( x_train , y_train_true)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LceU_zhQZD7v","colab_type":"code","colab":{},"outputId":"4d393325-1fca-4a33-82fb-d9e27952bb71"},"source":["# for op\n","df2 = data_op  ##############################################################################\n","\n","train, test = train_test_split(df2, test_size=0.1)\n","\n","y_train_true = train.iloc[:,[0]]\n","\n","y_test_true = test.iloc[:,[0]]\n","\n","x_train = train.iloc[:,1:8] #- with OP extra3----------------------------------------------\n","\n","x_test = test.iloc[:,1: 8]\n","\n","print( x_train , y_train_true)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["     0   1  0.1  0.2\n","22   0   1    0    0\n","5    1   5    1    0\n","98   1  10    0    1\n","12   0   1    0    0\n","117  2   7    1    2\n","37   2   1    2    4\n","90   2   5    2    0\n","26   2   8    0    2\n","69   2   8    0    2\n","11   0   1    0    0\n","120  0   1    0    0\n","49   2   1    2    0\n","122  0   1    0    0\n","111  0   1    0    0\n","109  0   1    0    0\n","126  0   1    0    0\n","51   1   8    0    1\n","78   4   2    8    4\n","9    1   3    1    0\n","67   2   2    3    0\n","40   4   8    4    6\n","94   1   8    0    1\n","101  2   8    0    4\n","21   2   2    2    0\n","46   0   1    0    0\n","24   4  10    1    4\n","60   0   1    0    0\n","13   0   1    0    0\n","131  0   1    0    0\n","119  2   7    0    4\n","..  ..  ..  ...  ...\n","81   2   3    2    2\n","33   2   7    0    3\n","4    0   1    0    0\n","100  0   1    0    0\n","87   0   1    0    0\n","47   0   1    0    0\n","23   0   1    0    0\n","110  2   3    2    0\n","6    0   1    0    0\n","105  1   9    0    1\n","74   2   5    2    4\n","79   4   1    4    0\n","43   0   1    0    0\n","116  1   9    0    1\n","121  2   8    1    2\n","18   1   3    1    0\n","73   4   3   10   16\n","15   1   4    1    0\n","114  0   1    0    0\n","130  0   1    0    0\n","129  0   1    0    0\n","63   0   1    0    0\n","83   0   1    0    0\n","39   1   7    0    1\n","61   0   1    0    0\n","82   4   4    6    0\n","56   2   6    2    4\n","42   2   1    3    3\n","96   2   9    0    3\n","52   0   1    0    0\n","\n","[118 rows x 4 columns]      3\n","22   2\n","5    1\n","98   2\n","12   1\n","117  2\n","37   1\n","90   3\n","26   1\n","69   1\n","11   3\n","120  1\n","49   2\n","122  3\n","111  2\n","109  2\n","126  1\n","51   3\n","78   3\n","9    3\n","67   2\n","40   1\n","94   3\n","101  2\n","21   2\n","46   2\n","24   3\n","60   3\n","13   3\n","131  2\n","119  2\n","..  ..\n","81   3\n","33   1\n","4    2\n","100  2\n","87   2\n","47   2\n","23   1\n","110  2\n","6    2\n","105  1\n","74   3\n","79   3\n","43   1\n","116  1\n","121  3\n","18   3\n","73   3\n","15   1\n","114  2\n","130  1\n","129  2\n","63   1\n","83   1\n","39   2\n","61   1\n","82   2\n","56   3\n","42   2\n","96   3\n","52   1\n","\n","[118 rows x 1 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M9sTi7zUZD7y","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b_FNiR9IZD70","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"INrn-z-5ZD72","colab_type":"text"},"source":["# GRID SEARCH hyperparameter tuning"]},{"cell_type":"markdown","metadata":{"id":"sdeQp9nmZD73","colab_type":"text"},"source":["# GENERAL MODEL fit & Training cell"]},{"cell_type":"code","metadata":{"id":"ek2s4boVZD74","colab_type":"code","colab":{},"outputId":"90fab3b9-658d-4177-f74a-f4d9a95aa058"},"source":["'''\n","x_train =  #-----------------------------------------------\n","\n","x_test = \n","\n","y_train_true = \n","y_test_pred\n","y_test_true =  #----------------------------------------\n","'''\n","model.fit(x_train, y_train_true.values.ravel()) ###########################################\n","\n","#mean absolute value for training data\n","##data = train[target]\n","\n"," \n"," \n","##predict =  model.predict(train[features])\n","y_train_pred =  model.predict(x_train)  #--------------------------------------------------\n","\n","\n","\n","print (y_train_true.values.ravel(),y_train_pred)\n","\n","y_test_pred = model.predict(x_test)\n","\n","print(y_test_true.values.ravel(), y_test_pred)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[2 2 1 2 1 2 1 3 2 3 3 1 2 2 1 3 1 1 1 1 3 1 3 3 1 3 3 1 3 3 2 3 3 3 3 2 1\n"," 2 3 1 3 3 3 1 3 3 2 3 1 1 3 2 3 3 3 1 2 1 1 3 2 2 3 2 3 2 3 2 1 2 3 3 2 2\n"," 1 2 3 2 3 1 3 1 2 1 3 3 1 1 2 2 3 1 1 1 3 2 2 1 1 1 3 2 1 1 1 2 3 3 1 1 2\n"," 3 2 1 1 2 1 1] [3 2 3 2 1 2 3 3 2 3 3 2 1 3 1 1 1 3 1 1 1 1 3 3 1 3 3 3 1 3 1 1 3 3 3 1 1\n"," 1 3 1 3 3 3 1 1 3 3 3 1 1 1 1 2 3 3 1 1 1 1 3 2 2 3 2 3 3 3 1 1 2 1 2 1 1\n"," 1 3 3 1 3 2 3 3 3 1 2 3 1 1 1 1 3 1 1 1 3 1 3 3 2 2 3 3 1 1 3 3 3 3 1 1 1\n"," 2 2 1 1 3 1 1]\n","[1 1 3 2 2 2 1 1 1 1 3 1 2 3] [3 2 2 1 2 3 2 1 1 2 3 1 1 1]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rEi46-zgZD76","colab_type":"code","colab":{},"outputId":"88ca865a-a948-4673-f761-ace9e9f795f5"},"source":["accuracy = r2_score(y_test_true, y_test_pred)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'r2_score' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-8858143ba600>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'r2_score' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"-vv_VNsbZD78","colab_type":"text"},"source":["# accuracy cell "]},{"cell_type":"code","metadata":{"id":"HIsVntOEZD79","colab_type":"code","colab":{},"outputId":"286c0cdc-3d72-40fc-98e2-84cb07044ef5"},"source":["from sklearn import metrics\n","print(\"Accuracy:\",metrics.accuracy_score(y_test_true, y_test_pred))\n","\n","print(\"Train Accuracy:\",metrics.accuracy_score(y_train_true, y_train_pred))\n","\n","\n","from sklearn.metrics import confusion_matrix \n","from sklearn.metrics import accuracy_score \n","from sklearn.metrics import classification_report \n","\n","results = confusion_matrix(y_test_true, y_test_pred)\n","print ('Confusion Matrix :')\n","print(results) \n","print ('Accuracy Score :',accuracy_score(y_test_true, y_test_pred) ) \n","print ('Report : ')\n","print (classification_report(y_test_true, y_test_pred) )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy: 0.357142857143\n","Train Accuracy: 0.610169491525\n","Confusion Matrix :\n","[[3 3 1]\n"," [2 1 1]\n"," [1 1 1]]\n","Accuracy Score : 0.357142857143\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.50      0.43      0.46         7\n","          2       0.20      0.25      0.22         4\n","          3       0.33      0.33      0.33         3\n","\n","avg / total       0.38      0.36      0.37        14\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mY3-BYICZD7_","colab_type":"text"},"source":["# K-fold cross validation training & score"]},{"cell_type":"code","metadata":{"id":"_Zr4nsZPZD8A","colab_type":"code","colab":{},"outputId":"e53db73a-776e-4d26-ebe1-8dfff441ab45"},"source":["from sklearn.model_selection import cross_val_score\n","#scores = cross_val_score(model , X = x_train , y = y_train_true , cv = x_train.shape[0]) \n","scores = cross_val_score(model , X = x_train , y = y_train_true.values.ravel() , cv = 30) \n","print (scores)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[ 0.33333333  0.          0.5         0.6         0.4         0.4         0.8\n","  0.6         0.6         0.4         0.8         0.2         1.          0.\n","  0.33333333  1.          0.33333333  0.          0.          0.33333333\n","  0.33333333  0.66666667  0.33333333  0.33333333  0.66666667  0.66666667\n","  0.33333333  0.33333333  1.          0.33333333]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tycCVTPJZD8C","colab_type":"text"},"source":["data_avn = pd.read_csv('wml_avn_label.csv', header = 0)\n","\n","data_fan = pd.read_csv('wml_fan_label.csv', header = 0)\n","\n","data_avn_fan = pd.read_csv('wml_avn_fan_label.csv', header = 0)\n","\n","data_avn_fan_op = pd.read_csv('wml_avn_fan_op_label.csv', header = 0)\n","\n","data_op "]},{"cell_type":"markdown","metadata":{"id":"1C7mmPiFZD8D","colab_type":"text"},"source":["# LEAVE ONE OUT USING SVM (named as model) 100%  data ONLY AVN & FAN"]},{"cell_type":"code","metadata":{"id":"CISm9NpJZD8E","colab_type":"code","colab":{}},"source":["'''\n","parameter_candidates = [\n","  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n","  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n","]\n","# Create a classifier object with the classifier and parameter candidates\n","model = GridSearchCV(estimator=svm.SVC(), param_grid=parameter_candidates, n_jobs=-1)\n","'''\n","parameter_candidates = [\n","  {'C': [ 100], 'kernel': ['linear'] }\n","\n","]\n","# Create a classifier object with the classifier and parameter candidates\n","model = GridSearchCV(estimator=svm.SVC(), param_grid=parameter_candidates, n_jobs=-1)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SjyNdY6QZD8G","colab_type":"code","colab":{},"outputId":"1e13f896-fd3a-46f8-df39-c3cc279d907b"},"source":["\n","\n","from sklearn.model_selection import LeaveOneOut ########LEAVE ONE OUT\n","import numpy as np\n","#x = np.array([[1, 2], [3, 4]])\n","x_train = data_avn_fan.iloc[:,1:17] #----------------\n","y_train = data_avn_fan.iloc[:,[0]]\n","\n","\n","x = np.array(x_train)\n","y = np.array(y_train.values.ravel())\n","\n","############# Standard Scalar\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","#scaler.fit_transform(x.values.reshape(-1, 1))\n","x = scaler.fit_transform(x)\n","#X_test = scaler.transform(X_test)\n","\n","loo = LeaveOneOut()\n","loo.get_n_splits(x)\n","# x_train mane whole data nea dorkar ekhane\n","for train_index, test_index in loo.split(x):\n","        #print(\"train:\", train_index, \"validation:\", test_index)\n","        x_train, x_test = x[train_index], x[test_index]\n","        y_train, y_test = y[train_index], y[test_index]\n","        \n","        \n","        model.fit(x_train, y_train.ravel())\n","        y_train_pred =  model.predict(x_train)  #--------------------------------------------------\n","        #print (y_train_true.values.ravel(),y_train_pred)\n","\n","        #y_test_pred = model.predict(x_test)        \n","#model.fit(x_train, y_train_true.values.ravel()) ###########################################\n","\n","print('Best C:',model.best_estimator_.C) \n","print('Best Kernel:',model.best_estimator_.kernel)\n","print('Best Gamma:',model.best_estimator_.gamma)\n","\n","from sklearn import metrics\n","from sklearn.metrics import confusion_matrix \n","from sklearn.metrics import accuracy_score \n","from sklearn.metrics import classification_report \n","\n","print(\"Train Accuracy:\",metrics.accuracy_score(y_train, y_train_pred))\n","\n","results = confusion_matrix(y_train, y_train_pred)\n","print ('Confusion Matrix :')\n","print(results) \n","print ('Accuracy Score :',accuracy_score(y_train, y_train_pred) ) \n","print ('Report : ')\n","print (classification_report(y_train, y_train_pred) )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Best C: 100\n","Best Kernel: linear\n","Best Gamma: auto\n","Train Accuracy: 0.740458015267\n","Confusion Matrix :\n","[[31 18]\n"," [16 66]]\n","Accuracy Score : 0.740458015267\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.66      0.63      0.65        49\n","          2       0.79      0.80      0.80        82\n","\n","avg / total       0.74      0.74      0.74       131\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"w7BlKDBRZD8J","colab_type":"text"},"source":["# SVM model(GRID search scaler) AVN, FAN_class 2\n","Best C: 100\n","Best Kernel: linear\n","Best Gamma: auto\n","Train Accuracy: 0.740458015267\n","Confusion Matrix :\n","[[31 18]\n"," [16 66]]\n","Accuracy Score : 0.740458015267\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.66      0.63      0.65        49\n","          2       0.79      0.80      0.80        82\n","\n","avg / total       0.74      0.74      0.74       131\n","# SVM model AVN, FAN, OP\n","Train Accuracy: 0.770992366412\n","Confusion Matrix :\n","[[36 13]\n"," [17 65]]\n","Accuracy Score : 0.770992366412\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.68      0.73      0.71        49\n","          2       0.83      0.79      0.81        82\n","\n","avg / total       0.78      0.77      0.77       131\n","# SVM model AVN\n","Train Accuracy: 0.679389312977\n","Confusion Matrix :\n","[[31 18]\n"," [24 58]]\n","Accuracy Score : 0.679389312977\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.56      0.63      0.60        49\n","          2       0.76      0.71      0.73        82\n","\n","avg / total       0.69      0.68      0.68       131\n","# SVM model  FAN\n","Train Accuracy: 0.63358778626\n","Confusion Matrix :\n","[[ 2 47]\n"," [ 1 81]]\n","Accuracy Score : 0.63358778626\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.67      0.04      0.08        49\n","          2       0.63      0.99      0.77        82\n","\n","avg / total       0.65      0.63      0.51       131\n","# SVM model  OP\n","Train Accuracy: 0.625954198473\n","Confusion Matrix :\n","[[ 0 49]\n"," [ 0 82]]\n","Accuracy Score : 0.625954198473\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.00      0.00      0.00        49\n","          2       0.63      1.00      0.77        82\n","\n","avg / total       0.39      0.63      0.48       131"]},{"cell_type":"markdown","metadata":{"id":"DRXUkorZZD8J","colab_type":"text"},"source":["# SVM model AVN, FAN, OP "]},{"cell_type":"code","metadata":{"id":"v4uJBvuOZD8K","colab_type":"code","colab":{},"outputId":"411fd73c-b681-4289-e544-4d82f959d261"},"source":["'''\n","parameter_candidates = [\n","  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n","  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n","]\n","# Create a classifier object with the classifier and parameter candidates\n","model = GridSearchCV(estimator=svm.SVC(), param_grid=parameter_candidates, n_jobs=-1)\n","\n","\n","\n","from sklearn.model_selection import LeaveOneOut ########LEAVE ONE OUT\n","import numpy as np\n","\n","'''\n","#x = np.array([[1, 2], [3, 4]])\n","x_train = data_avn_fan_op.iloc[:,1:25] #----------------\n","y_train = data_avn_fan_op.iloc[:,[0]]\n","\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","x = np.array(x_train)\n","y = np.array(y_train.values.ravel())\n","\n","x = scaler.fit_transform(x)\n","\n","loo = LeaveOneOut()\n","loo.get_n_splits(x)\n","# x_train mane whole data nea dorkar ekhane\n","for train_index, test_index in loo.split(x):\n","        #print(\"train:\", train_index, \"validation:\", test_index)\n","        x_train, x_test = x[train_index], x[test_index]\n","        y_train, y_test = y[train_index], y[test_index]\n","        \n","        \n","        model.fit(x_train, y_train.ravel())\n","        y_train_pred =  model.predict(x_train)  #--------------------------------------------------\n","        \n","from sklearn import metrics\n","\n","print(\"Train Accuracy:\",metrics.accuracy_score(y_train, y_train_pred))\n","\n","\n","from sklearn.metrics import confusion_matrix \n","from sklearn.metrics import accuracy_score \n","from sklearn.metrics import classification_report \n","\n","results = confusion_matrix(y_train, y_train_pred)\n","print ('Confusion Matrix :')\n","print(results) \n","print ('Accuracy Score :',accuracy_score(y_train, y_train_pred) ) \n","print ('Report : ')\n","print (classification_report(y_train, y_train_pred) )"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'data_avn_fan_op' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-6d2c1abb6429>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m '''\n\u001b[1;32m     15\u001b[0m \u001b[1;31m#x = np.array([[1, 2], [3, 4]])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_avn_fan_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#----------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_avn_fan_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'data_avn_fan_op' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"NCQJQugzZD8M","colab_type":"text"},"source":["# SVM & AVN"]},{"cell_type":"code","metadata":{"id":"TrF-fuPpZD8N","colab_type":"code","colab":{},"outputId":"cc2647ca-1a0c-46fc-aebd-e30c2725d640"},"source":["x_train = data_avn.iloc[:,1:8] #----------------\n","y_train = data_avn.iloc[:,[0]]\n","\n","\n","x = np.array(x_train)\n","y = np.array(y_train.values.ravel())\n","\n","x = scaler.fit_transform(x)\n","\n","loo = LeaveOneOut()\n","loo.get_n_splits(x)\n","# x_train mane whole data nea dorkar ekhane\n","for train_index, test_index in loo.split(x):\n","        #print(\"train:\", train_index, \"validation:\", test_index)\n","        x_train, x_test = x[train_index], x[test_index]\n","        y_train, y_test = y[train_index], y[test_index]\n","        \n","        \n","        model.fit(x_train, y_train.ravel())\n","        y_train_pred =  model.predict(x_train)  #--------------------------------------------------\n","        \n","\n","print(\"Train Accuracy:\",metrics.accuracy_score(y_train, y_train_pred))\n","\n","results = confusion_matrix(y_train, y_train_pred)\n","print ('Confusion Matrix :')\n","print(results) \n","print ('Accuracy Score :',accuracy_score(y_train, y_train_pred) ) \n","print ('Report : ')\n","print (classification_report(y_train, y_train_pred) )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train Accuracy: 0.679389312977\n","Confusion Matrix :\n","[[31 18]\n"," [24 58]]\n","Accuracy Score : 0.679389312977\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.56      0.63      0.60        49\n","          2       0.76      0.71      0.73        82\n","\n","avg / total       0.69      0.68      0.68       131\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wVkORfOtZD8Q","colab_type":"text"},"source":["# SVM_ & FAN  OP combinations "]},{"cell_type":"code","metadata":{"id":"NiqSDQXCZD8U","colab_type":"code","colab":{},"outputId":"f1a28d32-bec1-4f7d-9f27-b56ab1572d71"},"source":["#x_train = data_op.iloc[:,1:8] #----------------\n","#y_train = data_op.iloc[:,[0]]\n","import numpy as np\n","data_avn_op = pd.read_csv('op_avn_label.csv', header = 0)\n","data_fan_op = pd.read_csv('op_fan_label.csv', header = 0)\n","x_train = data_fan_op.iloc[:,1:16] #----------------\n","y_train = data_fan_op.iloc[:,[0]]\n","\n","x = np.array(x_train)\n","y = np.array(y_train.values.ravel())\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","x = scaler.fit_transform(x)\n","\n","loo = LeaveOneOut()\n","loo.get_n_splits(x)\n","# x_train mane whole data nea dorkar ekhane\n","for train_index, test_index in loo.split(x):\n","        #print(\"train:\", train_index, \"validation:\", test_index)\n","        x_train, x_test = x[train_index], x[test_index]\n","        y_train, y_test = y[train_index], y[test_index]\n","        \n","        \n","        model.fit(x_train, y_train.ravel())\n","        y_train_pred =  model.predict(x_train)  #--------------------------------------------------\n","        \n","from sklearn import metrics\n","\n","print(\"Train Accuracy:\",metrics.accuracy_score(y_train, y_train_pred))\n","\n","\n","from sklearn.metrics import confusion_matrix \n","from sklearn.metrics import accuracy_score \n","from sklearn.metrics import classification_report \n","\n","results = confusion_matrix(y_train, y_train_pred)\n","print ('Confusion Matrix :')\n","print(results) \n","print ('Accuracy Score :',accuracy_score(y_train, y_train_pred) ) \n","print ('Report : ')\n","y_train_pred =  model.predict(x_train)\n","print (classification_report(y_train, y_train_pred) )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train Accuracy: 0.664122137405\n","Confusion Matrix :\n","[[24 25]\n"," [19 63]]\n","Accuracy Score : 0.664122137405\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.56      0.49      0.52        49\n","          2       0.72      0.77      0.74        82\n","\n","avg / total       0.66      0.66      0.66       131\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fpdx2btKZD8c","colab_type":"text"},"source":["op_Avn\n","Train Accuracy: 0.679389312977\n","Confusion Matrix :\n","[[27 22]\n"," [20 62]]\n","Accuracy Score : 0.679389312977\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.57      0.55      0.56        49\n","          2       0.74      0.76      0.75        82\n","\n","avg / total       0.68      0.68      0.68       131\n","OP_FAN\n","Accuracy: 0.664122137405\n","Confusion Matrix :\n","[[24 25]\n"," [19 63]]\n","Accuracy Score : 0.664122137405\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.56      0.49      0.52        49\n","          2       0.72      0.77      0.74        82\n","\n","avg / total       0.66      0.66      0.66       131"]},{"cell_type":"markdown","metadata":{"id":"AR2SdpYXZD8c","colab_type":"text"},"source":["# Random forest ----leave one out & AVN_FAN"]},{"cell_type":"code","metadata":{"id":"3h5hM1zMZD8d","colab_type":"code","colab":{},"outputId":"289e7c47-6e2e-4862-8949-4e931f9ef24f"},"source":["#Import Random Forest Model\n","from sklearn.ensemble import RandomForestClassifier\n","\n","clf=RandomForestClassifier(n_estimators=400)\n","model = clf\n","\n","#clf.fit(x_train,y_train_true)\n","#y_test_pred=clf.predict(x_test)\n","#x_train = data_avn_fan.iloc[:,1:17]\n","#x_train = data_avn.iloc[:,1:8] #----------------\n","#y_train = data_avn.iloc[:,[0]]\n","import numpy as np\n","data_avn_op = pd.read_csv('op_avn_label.csv', header = 0)\n","data_fan_op = pd.read_csv('op_fan_label.csv', header = 0)\n","x_train = data_fan_op.iloc[:,1:16] #----------------\n","y_train = data_fan_op.iloc[:,[0]]\n","\n","x = np.array(x_train)\n","y = np.array(y_train.values.ravel())\n","'''\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","x = scaler.fit_transform(x)\n","'''\n","\n","loo = LeaveOneOut()\n","loo.get_n_splits(x)\n","for train_index, test_index in loo.split(x):\n","        #print(\"train:\", train_index, \"validation:\", test_index)\n","        x_train, x_test = x[train_index], x[test_index]\n","        y_train, y_test = y[train_index], y[test_index]\n","        \n","        \n","        model.fit(x_train, y_train.ravel())\n","        y_train_pred =  model.predict(x_train)  #--------------------------------------------------\n","        #print (y_train_true.values.ravel(),y_train_pred)\n","\n","        #y_test_pred = model.predict(x_test)        \n","#model.fit(x_train, y_train_true.values.ravel()) ###########################################\n","\n","from sklearn import metrics\n","from sklearn.metrics import confusion_matrix \n","from sklearn.metrics import accuracy_score \n","from sklearn.metrics import classification_report \n","\n","print(\"Train Accuracy:\",metrics.accuracy_score(y_train, y_train_pred))\n","\n","results = confusion_matrix(y_train, y_train_pred)\n","print ('Confusion Matrix :')\n","print(results) \n","print ('Accuracy Score :',accuracy_score(y_train, y_train_pred) ) \n","\n","y_train_pred =  model.predict(x)\n","print ('Report : ')\n","#print (classification_report(y_train, y_train_pred) )\n","print (classification_report(y, y_train_pred) )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train Accuracy: 0.793893129771\n","Confusion Matrix :\n","[[45  4]\n"," [23 59]]\n","Accuracy Score : 0.793893129771\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.65      0.92      0.76        49\n","          2       0.94      0.71      0.81        83\n","\n","avg / total       0.83      0.79      0.79       132\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"igJc8U8iZD8f","colab_type":"text"},"source":["# Random Forest model AVN, FAN_class 2\n","Train Accuracy: 0.885496183206\n","Confusion Matrix :\n","[[45  4]\n"," [11 71]]\n","Accuracy Score : 0.885496183206\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.80      0.92      0.86        49\n","          2       0.95      0.87      0.90        82\n","\n","avg / total       0.89      0.89      0.89       131\n","# Random Forest model AVN, FAN, OP\n","Train Accuracy: 0.916030534351\n","Confusion Matrix :\n","[[47  2]\n"," [ 9 73]]\n","Accuracy Score : 0.916030534351\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.84      0.96      0.90        49\n","          2       0.97      0.89      0.93        82\n","\n","avg / total       0.92      0.92      0.92       131\n","# Random Forest model AVN\n","Train Accuracy: 0.725190839695\n","Confusion Matrix :\n","[[39 10]\n"," [26 56]]\n","Accuracy Score : 0.725190839695\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.60      0.80      0.68        49\n","          2       0.85      0.68      0.76        82\n","\n","avg / total       0.76      0.73      0.73       131\n","# Random Forest model  FAN\n","Train Accuracy: 0.763358778626\n","Confusion Matrix :\n","[[42  7]\n"," [24 58]]\n","Accuracy Score : 0.763358778626\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.64      0.86      0.73        49\n","          2       0.89      0.71      0.79        82\n","\n","avg / total       0.80      0.76      0.77       131\n","# Random Forest model  OP\n","Train Accuracy: 0.75572519084\n","Confusion Matrix :\n","[[19 30]\n"," [ 2 80]]\n","Accuracy Score : 0.75572519084\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.90      0.39      0.54        49\n","          2       0.73      0.98      0.84        83\n","\n","avg / total       0.79      0.76      0.73       132\n","# OP_AVN\n"," Accuracy: 0.854961832061\n","Confusion Matrix :\n","[[39 10]\n"," [ 9 73]]\n","Accuracy Score : 0.854961832061\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.80      0.80      0.80        49\n","          2       0.88      0.88      0.88        83\n","\n","avg / total       0.85      0.85      0.85       132\n","# OP_FAN\n","Accuracy: 0.793893129771\n","Confusion Matrix :\n","[[45  4]\n"," [23 59]]\n","Accuracy Score : 0.793893129771\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.65      0.92      0.76        49\n","          2       0.94      0.71      0.81        83\n","\n","avg / total       0.83      0.79      0.79       132"]},{"cell_type":"markdown","metadata":{"id":"6Q-znMWrZD8g","colab_type":"text"},"source":["# ERROR for REGression"]},{"cell_type":"code","metadata":{"id":"n9I3VLwzZD8h","colab_type":"code","colab":{}},"source":["\n","\n","\n","test_data_error = mean_absolute_error(y_test_true, y_test_pred)\n","accuracy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E5bW59axZD8j","colab_type":"code","colab":{},"outputId":"6f538d15-a93d-49ab-c77e-a860a618e053"},"source":["#define model I am using\n","model = LinearRegression()\n","#training process\n","##model.fit(train[features], train[target])\n","from sklearn.metrics import f1_score\n","\n","model.fit(data_avn, target_1col)\n","#mean absolute value for training data\n","##data = train[target]\n","true_target = target_1col\n","##predict =  model.predict(train[features])\n","predict =  model.predict(data_avn)\n","\n","\n","training_error = mean_absolute_error(true_target, predict)\n","accuracy = r2_score(true_target, predict)\n","#accuracy = f1_score(true_target, predict, average='micro')\n","print(predict)\n","accuracy\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[  2799.4262873 ]\n"," [  2833.22335692]\n"," [  2492.58545066]\n"," [  2551.87960068]\n"," [  2000.29881734]\n"," [  2124.05002439]\n"," [  2365.65288887]\n"," [  2001.82331314]\n"," [  5050.11742108]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [ 13033.93275207]\n"," [  2688.02791551]\n"," [  3862.24907869]\n"," [  2365.65288887]\n"," [  2336.39627142]\n"," [  2773.44160075]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [  1526.43521463]\n"," [  1286.09171366]\n"," [  2034.09588696]\n"," [  7713.61507356]\n"," [  1873.36625554]\n"," [  3045.56960396]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [  1032.22659007]\n"," [  6963.05424183]\n"," [  2619.51801246]\n"," [  1873.36625554]\n"," [  2709.47214988]\n"," [  3975.29906205]\n"," [  1873.36625554]\n"," [  2463.32883322]\n"," [  2828.68290475]\n"," [  2336.39627142]\n"," [  2799.4262873 ]\n"," [  5239.91840605]\n"," [  1661.02000851]\n"," [  2364.06560477]\n"," [  1873.36625554]\n"," [  3484.2580694 ]\n"," [  2000.29881734]\n"," [  3987.65714468]\n"," [  3387.98549501]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [  7222.13449587]\n"," [  3062.46813877]\n"," [  4896.28629751]\n"," [   258.68106384]\n"," [  1873.36625554]\n"," [  2336.39627142]\n"," [  3997.12482753]\n"," [  2000.29881734]\n"," [  2824.04662904]\n"," [  1873.36625554]\n"," [  2336.39627142]\n"," [  1873.36625554]\n"," [  2795.37390671]\n"," [  1924.06185998]\n"," [  1873.36625554]\n"," [  2799.4262873 ]\n"," [ 10368.40054348]\n"," [  2336.39627142]\n"," [  2000.29881734]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [  1755.67999648]\n"," [  1873.36625554]\n"," [  1032.22659007]\n"," [  1873.36625554]\n"," [  6247.81596131]\n"," [  1873.36625554]\n"," [  5057.32994471]\n"," [  1873.36625554]\n"," [  3044.166234  ]\n"," [  4178.33621806]\n"," [  2119.50957221]\n"," [  4844.71395442]\n"," [  1873.36625554]\n"," [   592.22963183]\n"," [  2000.29881734]\n"," [  2000.29881734]\n"," [  1873.36625554]\n"," [  5469.1631879 ]\n"," [  2365.65288887]\n"," [  1873.36625554]\n"," [   191.08692459]\n"," [  2984.87208399]\n"," [  1873.36625554]\n"," [  3997.12482753]\n"," [  2136.40810702]\n"," [  2336.39627142]\n"," [  1873.36625554]\n"," [  1644.1214737 ]\n"," [  3044.166234  ]\n"," [  5297.78523354]\n"," [  3053.29141089]\n"," [  1873.36625554]\n"," [  2218.71001236]\n"," [  2799.4262873 ]\n"," [  1873.36625554]\n"," [  1897.98659728]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [  1873.36625554]\n"," [  3754.7429365 ]\n"," [  2246.442134  ]\n"," [  1873.36625554]\n"," [  1897.98659728]\n"," [  2127.23137913]\n"," [  5239.91840605]]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["0.39671025891021217"]},"metadata":{"tags":[]},"execution_count":83}]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"BylOBR9CZD8m","colab_type":"text"},"source":["from sklearn.linear_model import LogisticRegression\n","model = LogisticRegression(solver = 'lbfgs')\n","model.fit(train_img, train_lbl)\n","y_pred = model.predict(test_img)\n","# how did our model perform?\n","count_misclassified = (test_lbl != y_pred).sum()\n","print('Misclassified samples: {}'.format(count_misclassified))\n","accuracy = metrics.accuracy_score(test_lbl, y_pred)\n","print('Accuracy: {:.2f}'.format(accuracy))\n"]},{"cell_type":"markdown","metadata":{"id":"RPadvHmCZD8m","colab_type":"text"},"source":["Logistic Regression for multiclass"]},{"cell_type":"code","metadata":{"id":"T7yAC8QcZD8n","colab_type":"code","colab":{},"outputId":"3ad5b61a-7374-4ee2-b8fb-4544570a5f63"},"source":["from sklearn.model_selection import LeaveOneOut ########LEAVE ONE OUT\n","import numpy as np\n","from sklearn.linear_model import LogisticRegression\n","\n","\n","model = LogisticRegression(solver = 'lbfgs')\n","\n","#clf.fit(x_train,y_train_true)\n","#y_test_pred=clf.predict(x_test)\n","#x_train = data_avn_fan.iloc[:,1:17]\n","'''\n","x_train = data_op.iloc[:,1:8] #----------------\n","y_train = data_op.iloc[:,[0]]\n","'''\n","import numpy as np\n","data_avn_op = pd.read_csv('op_avn_label.csv', header = 0)\n","data_fan_op = pd.read_csv('op_fan_label.csv', header = 0)\n","x_train = data_avn_op.iloc[:,1:16] #----------------\n","y_train = data_avn_op.iloc[:,[0]]\n","\n","x = np.array(x_train)\n","y = np.array(y_train.values.ravel())\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","x = scaler.fit_transform(x)\n","\n","x2 = np.array(x_train)\n","y = np.array(y_train.values.ravel())\n","x = scaler.fit_transform(x2) # with or without same result\n","\n","loo = LeaveOneOut()\n","loo.get_n_splits(x)\n","for train_index, test_index in loo.split(x):\n","        #print(\"train:\", train_index, \"validation:\", test_index)\n","        x_train, x_test = x[train_index], x[test_index]\n","        y_train, y_test = y[train_index], y[test_index]\n","        \n","        \n","        model.fit(x_train, y_train.ravel())\n","        y_train_pred =  model.predict(x_train)  #--------------------------------------------------\n","        #print (y_train_true.values.ravel(),y_train_pred)\n","\n","        #y_test_pred = model.predict(x_test)        \n","#model.fit(x_train, y_train_true.values.ravel()) ###########################################\n","\n","from sklearn import metrics\n","from sklearn.metrics import confusion_matrix \n","from sklearn.metrics import accuracy_score \n","from sklearn.metrics import classification_report \n","\n","print(\"Train Accuracy:\",metrics.accuracy_score(y_train, y_train_pred))\n","\n","results = confusion_matrix(y_train, y_train_pred)\n","print ('Confusion Matrix :')\n","print(results) \n","print ('Accuracy Score :',accuracy_score(y_train, y_train_pred) ) \n","print ('Report : ')\n","print (classification_report(y_train, y_train_pred) )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train Accuracy: 0.656488549618\n","Confusion Matrix :\n","[[19 30]\n"," [15 67]]\n","Accuracy Score : 0.656488549618\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.56      0.39      0.46        49\n","          2       0.69      0.82      0.75        82\n","\n","avg / total       0.64      0.66      0.64       131\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uUjDeyM2ZD8p","colab_type":"text"},"source":["Train Accuracy: 0.664122137405\n","Confusion Matrix :\n","[[26 23]\n"," [21 61]]\n","Accuracy Score : 0.664122137405\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.55      0.53      0.54        49\n","          2       0.73      0.74      0.73        82\n","\n","avg / total       0.66      0.66      0.66       131\n","\n","#avn_Op\n","Train Accuracy: 0.656488549618\n","Confusion Matrix :\n","[[19 30]\n"," [15 67]]\n","Accuracy Score : 0.656488549618\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.56      0.39      0.46        49\n","          2       0.69      0.82      0.75        82\n","\n","avg / total       0.64      0.66      0.64       131"]},{"cell_type":"markdown","metadata":{"id":"GfElrdQ6ZD8p","colab_type":"text"},"source":["# logistic Regression\n","# avn,fan,op\n","Train Accuracy: 0.717557251908\n","Confusion Matrix :\n","[[26 23]\n"," [14 68]]\n","Accuracy Score : 0.717557251908\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.65      0.53      0.58        49\n","          2       0.75      0.83      0.79        82\n","\n","avg / total       0.71      0.72      0.71       131\n","# avn_fan\n","Train Accuracy: 0.748091603053\n","Confusion Matrix :\n","[[29 20]\n"," [13 69]]\n","Accuracy Score : 0.748091603053\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.69      0.59      0.64        49\n","          2       0.78      0.84      0.81        82\n","\n","avg / total       0.74      0.75      0.74       131\n","# avn\n","Train Accuracy: 0.664122137405\n","Confusion Matrix :\n","[[27 22]\n"," [22 60]]\n","Accuracy Score : 0.664122137405\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.55      0.55      0.55        49\n","          2       0.73      0.73      0.73        82\n","\n","avg / total       0.66      0.66      0.66       131\n","# fan\n","Train Accuracy: 0.641221374046\n","Confusion Matrix :\n","[[ 4 45]\n"," [ 2 80]]\n","Accuracy Score : 0.641221374046\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.67      0.08      0.15        49\n","          2       0.64      0.98      0.77        82\n","\n","avg / total       0.65      0.64      0.54       131\n","# op\n","Accuracy: 0.641221374046\n","Confusion Matrix :\n","[[ 2 47]\n"," [ 0 82]]\n","Accuracy Score : 0.641221374046\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       1.00      0.04      0.08        49\n","          2       0.64      1.00      0.78        82\n","\n","avg / total       0.77      0.64      0.52       131"]},{"cell_type":"code","metadata":{"id":"THptE38qZD8q","colab_type":"code","colab":{}},"source":["from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import LeaveOneOut ########LEAVE ONE OUT\n","import numpy as np\n","parameters = {'solver': ['lbfgs'], 'max_iter': [1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000 ], 'alpha': 10.0 ** -np.arange(1, 10), 'hidden_layer_sizes':np.arange(10, 15), 'random_state':[0,1,2,3,4,5,6,7,8,9]}\n","model = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1)\n","'''\n","print('Best C:',model.best_estimator_.C) \n","print('Best Kernel:',model.best_estimator_.kernel)\n","print('Best Gamma:',model.best_estimator_.gamma)\n","'''"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bwW56TLuZD8s","colab_type":"text"},"source":["# M L P neural network"]},{"cell_type":"code","metadata":{"id":"6169rdnTZD8t","colab_type":"code","colab":{},"outputId":"11977906-b05e-48d0-a0ec-2962264e131b"},"source":["from sklearn.neural_network import MLPClassifier\n","import numpy as np\n","from sklearn.model_selection import LeaveOneOut ########LEAVE ONE OUT\n","\n","model = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(100,100,100))\n"," ##For small datasets, however, lbfgs can converge faster and perform better.\n","\n","x_train = data_avn_fan_op.iloc[:,1:25] #----------------\n","y_train = data_avn_fan_op.iloc[:,[0]]\n","\n","\n","x = np.array(x_train)\n","y = np.array(y_train.values.ravel())\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","x = scaler.fit_transform(x)\n","\n","loo = LeaveOneOut()\n","loo.get_n_splits(x)\n","for train_index, test_index in loo.split(x):\n","        #print(\"train:\", train_index, \"validation:\", test_index)\n","        x_train, x_test = x[train_index], x[test_index]\n","        y_train, y_test = y[train_index], y[test_index]\n","        \n","        \n","        model.fit(x_train, y_train.ravel())\n","        y_train_pred =  model.predict(x_train)  #--------------------------------------------------\n","        #print (y_train_true.values.ravel(),y_train_pred)\n","\n","        #y_test_pred = model.predict(x_test)        \n","#model.fit(x_train, y_train_true.values.ravel()) ###########################################\n","\n","\n","from sklearn import metrics\n","from sklearn.metrics import confusion_matrix \n","from sklearn.metrics import accuracy_score \n","from sklearn.metrics import classification_report \n","\n","print(\"Train Accuracy:\",metrics.accuracy_score(y_train, y_train_pred))\n","\n","results = confusion_matrix(y_train, y_train_pred)\n","print ('Confusion Matrix :')\n","print(results) \n","print ('Accuracy Score :',accuracy_score(y_train, y_train_pred) ) \n","print ('Report : ')\n","print (classification_report(y_train, y_train_pred) )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train Accuracy: 0.916030534351\n","Confusion Matrix :\n","[[48  1]\n"," [10 72]]\n","Accuracy Score : 0.916030534351\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.83      0.98      0.90        49\n","          2       0.99      0.88      0.93        82\n","\n","avg / total       0.93      0.92      0.92       131\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ag0uohKLZD8v","colab_type":"text"},"source":["# MLP solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(100,100,100)\n","# avn fan op\n","Accuracy: 0.916030534351\n","Confusion Matrix :\n","[[48  1]\n"," [10 72]]\n","Accuracy Score : 0.916030534351\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.83      0.98      0.90        49\n","          2       0.99      0.88      0.93        82\n","\n","avg / total       0.93      0.92      0.92       131\n","# fan op\n","Confusion Matrix :\n","[[44  5]\n"," [22 60]]\n","Accuracy Score : 0.793893129771\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.67      0.90      0.77        49\n","          2       0.92      0.73      0.82        82\n","\n","avg / total       0.83      0.79      0.80       131\n","# avn op\n","Confusion Matrix :\n","[[39 10]\n"," [ 9 73]]\n","Accuracy Score : 0.854961832061\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.81      0.80      0.80        49\n","          2       0.88      0.89      0.88        82\n","\n","avg / total       0.85      0.85      0.85       131\n"," \n"," # avn fan\n","Confusion Matrix :\n","[[46  3]\n"," [12 70]]\n","Accuracy Score : 0.885496183206\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.79      0.94      0.86        49\n","          2       0.96      0.85      0.90        82\n","\n","avg / total       0.90      0.89      0.89       131 \n","# avn\n","Confusion Matrix :\n","[[39 10]\n"," [26 56]]\n","Accuracy Score : 0.725190839695\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.60      0.80      0.68        49\n","          2       0.85      0.68      0.76        82\n","\n","avg / total       0.76      0.73      0.73       131\n","# fan\n","Confusion Matrix :\n","[[43  6]\n"," [25 57]]\n","Accuracy Score : 0.763358778626\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.63      0.88      0.74        49\n","          2       0.90      0.70      0.79        82\n","\n","avg / total       0.80      0.76      0.77       131\n","# op\n","Confusion Matrix :\n","[[19 30]\n"," [ 2 80]]\n","Accuracy Score : 0.75572519084\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.90      0.39      0.54        49\n","          2       0.73      0.98      0.83        82\n","\n","avg / total       0.79      0.76      0.72       131\n"]},{"cell_type":"code","metadata":{"id":"VYFyy7VnZD8w","colab_type":"code","colab":{},"outputId":"ec577534-feb7-4773-c242-6fa74f8eb58b"},"source":["#x_train = data_op.iloc[:,1:8] #----------------\n","#y_train = data_op.iloc[:,[0]]\n","import numpy as np\n","data_avn_op = pd.read_csv('op_avn_label.csv', header = 0)\n","data_fan_op = pd.read_csv('op_fan_label.csv', header = 0)\n","x_train = data_op.iloc[:,1:8] #----------------\n","y_train = data_op.iloc[:,[0]]\n","model = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(100,100,100))\n","'''\n","data_avn = 1:8\n","\n","data_fan 1:8\n","\n","data_avn_fan  1:17\n","\n","data_avn_fan_op = 1:25\n","\n","data_op 1:8\n","'''"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ndata_avn = 1:8\\n\\ndata_fan 1:8\\n\\ndata_avn_fan  1:17\\n\\ndata_avn_fan_op = 1:25\\n\\ndata_op 1:8\\n'"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"ib5rPR7cZD8y","colab_type":"code","colab":{},"outputId":"950ae2e9-2f17-4e1e-a152-40154fe9b768"},"source":["x = np.array(x_train)\n","y = np.array(y_train.values.ravel())\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","x = scaler.fit_transform(x)\n","\n","loo = LeaveOneOut()\n","loo.get_n_splits(x)\n","# x_train mane whole data nea dorkar ekhane\n","for train_index, test_index in loo.split(x):\n","        #print(\"train:\", train_index, \"validation:\", test_index)\n","        x_train, x_test = x[train_index], x[test_index]\n","        y_train, y_test = y[train_index], y[test_index]\n","        \n","        \n","        model.fit(x_train, y_train.ravel())\n","        y_train_pred =  model.predict(x_train)  #--------------------------------------------------\n","        \n","from sklearn import metrics\n","from sklearn.metrics import confusion_matrix \n","from sklearn.metrics import accuracy_score \n","from sklearn.metrics import classification_report \n","\n","results = confusion_matrix(y_train, y_train_pred)\n","print ('Confusion Matrix :')\n","print(results) \n","print ('Accuracy Score :',accuracy_score(y_train, y_train_pred) ) \n","print ('Report : ')\n","y_train_pred =  model.predict(x_train)\n","print (classification_report(y_train, y_train_pred) )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Confusion Matrix :\n","[[19 30]\n"," [ 2 80]]\n","Accuracy Score : 0.75572519084\n","Report : \n","             precision    recall  f1-score   support\n","\n","          1       0.90      0.39      0.54        49\n","          2       0.73      0.98      0.83        82\n","\n","avg / total       0.79      0.76      0.72       131\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g6lLXfPhZD81","colab_type":"code","colab":{}},"source":["from sklearn import datasets\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt    \n","    \n","    plt.style.use('ggplot')\n","\n","from xgboost import XGBClassifier\n","from catboost import CatBoostClassifier\n","from lightgbm import LGBMClassifier\n","    \n","    # load the wine datasets\n","dataset = datasets.load_wine()\n","X = dataset.data; y = dataset.target\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n","    \n","    # fit a XGBoost model to the data\n","model = XGBClassifier()\n","model.fit(X_train, y_train)\n","print(); print(model)\n","    \n","    # make predictions\n","expected_y  = y_test\n","predicted_y = model.predict(X_test)\n","\n","    # summarize the fit of the model\n","print(); print('XGBoost: ')\n","print(); print(metrics.classification_report(expected_y, predicted_y, \n","                   target_names=dataset.target_names))\n","print(); print(metrics.confusion_matrix(expected_y, predicted_y))\n","\n","    # fit a CatBoost model to the data\n","model = CatBoostClassifier()\n","model.fit(X_train, y_train)\n","    print(); print(model)\n","\n","    # make predictions\n","expected_y  = y_test\n","predicted_y = model.predict(X_test)\n","\n","    # summarize the fit of the model\n","print(); print('CatBoost: ')\n","print(); print(metrics.classification_report(expected_y, predicted_y, \n","                   target_names=dataset.target_names))\n","print(); print(metrics.confusion_matrix(expected_y, predicted_y))\n","    \n","    # fit a LightGBM model to the data\n","model = LGBMClassifier()\n","model.fit(X_train, y_train)\n","print(); print(model)\n","\n","    # make predictions\n","expected_y  = y_test\n","predicted_y = model.predict(X_test)\n","    \n","    # summarize the fit of the model\n","print(); print('LightGBM: ')\n","print(); print(metrics.classification_report(expected_y, predicted_y, \n","                   target_names=dataset.target_names))\n","print(); print(metrics.confusion_matrix(expected_y, predicted_y))"],"execution_count":0,"outputs":[]}]}